{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8481f8d-147b-4996-91d8-46b997bd41f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Next WEEK 3QUERIES (PORTAL FORMAT) ===\n",
      "0.704820-0.153340\n",
      "0.696501-0.036321\n",
      "0.999243-0.782322-0.757237\n",
      "0.416966-0.404427-0.356931-0.406136\n",
      "0.014434-0.103845-0.991649-0.996046\n",
      "0.370837-0.173596-0.693576-0.962889-0.168614\n",
      "0.225757-0.439856-0.295544-0.723542-0.196561-0.797924\n",
      "0.063471-0.108669-0.036989-0.129464-0.927252-0.469168-0.101991-0.123106\n",
      "\n",
      "=== DIAGNOSTICS (kernel / xi-beta / explore-exploit) ===\n",
      "\n",
      "Function 1 (f1_2d_a): EXPLOIT | acquisition=EI | xi=0.001000 | beta=3.000\n",
      "  chosen_kernel: 1.01**2 * RBF(length_scale=[0.0159, 50]) + WhiteKernel(noise_level=8.6e-12)\n",
      "  best_LML: -14.813\n",
      "  mu(x*): 0.000030 | sigma(x*): 0.000919\n",
      "  exploration_ratio (proxy): 0.472\n",
      "  LML candidates:\n",
      "    - -14.813 :: 1.01**2 * RBF(length_scale=[0.0159, 50]) + WhiteKernel(noise_level=8.6e-12)\n",
      "    - -15.143 :: 1.01**2 * Matern(length_scale=[0.0163, 50], nu=1.5) + WhiteKernel(noise_level=3.27e-11)\n",
      "    - -15.015 :: 1.02**2 * Matern(length_scale=[0.0166, 50], nu=2.5) + WhiteKernel(noise_level=5.64e-10)\n",
      "\n",
      "Function 2 (f2_2d_b): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 1.08**2 * RBF(length_scale=[0.0477, 50]) + WhiteKernel(noise_level=0.0241)\n",
      "  best_LML: -12.798\n",
      "  mu(x*): 0.485199 | sigma(x*): 0.115722\n",
      "  exploration_ratio (proxy): 0.178\n",
      "  LML candidates:\n",
      "    - -12.798 :: 1.08**2 * RBF(length_scale=[0.0477, 50]) + WhiteKernel(noise_level=0.0241)\n",
      "    - -13.479 :: 1.04**2 * Matern(length_scale=[0.0478, 50], nu=1.5) + WhiteKernel(noise_level=0.0268)\n",
      "    - -13.242 :: 1.06**2 * Matern(length_scale=[0.049, 50], nu=2.5) + WhiteKernel(noise_level=0.0269)\n",
      "\n",
      "Function 3 (f3_3d): EXPLOIT | acquisition=EI | xi=0.001000 | beta=3.000\n",
      "  chosen_kernel: 1.8**2 * RBF(length_scale=[0.731, 50, 0.174]) + WhiteKernel(noise_level=0.0183)\n",
      "  best_LML: -14.118\n",
      "  mu(x*): 0.040129 | sigma(x*): 0.104177\n",
      "  exploration_ratio (proxy): 0.717\n",
      "  LML candidates:\n",
      "    - -14.118 :: 1.8**2 * RBF(length_scale=[0.731, 50, 0.174]) + WhiteKernel(noise_level=0.0183)\n",
      "    - -15.506 :: 2.54**2 * Matern(length_scale=[1.81, 50, 0.418], nu=1.5) + WhiteKernel(noise_level=0.0152)\n",
      "    - -14.711 :: 2.53**2 * Matern(length_scale=[1.48, 50, 0.312], nu=2.5) + WhiteKernel(noise_level=0.0168)\n",
      "\n",
      "Function 4 (f4_4d_a): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 4.67**2 * Matern(length_scale=[1.97, 1.84, 1.92, 1.9], nu=2.5) + WhiteKernel(noise_level=2.2e-12)\n",
      "  best_LML: -18.025\n",
      "  mu(x*): -1.645336 | sigma(x*): 0.720965\n",
      "  exploration_ratio (proxy): 0.298\n",
      "  LML candidates:\n",
      "    - -18.460 :: 2.21**2 * RBF(length_scale=[0.788, 0.727, 0.768, 0.757]) + WhiteKernel(noise_level=8.81e-11)\n",
      "    - -20.370 :: 7.35**2 * Matern(length_scale=[4.38, 4.09, 4.3, 4.28], nu=1.5) + WhiteKernel(noise_level=1.29e-11)\n",
      "    - -18.025 :: 4.67**2 * Matern(length_scale=[1.97, 1.84, 1.92, 1.9], nu=2.5) + WhiteKernel(noise_level=2.2e-12)\n",
      "\n",
      "Function 5 (f5_4d_b): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 4.47**2 * Matern(length_scale=[20.2, 50, 1.19, 0.753], nu=2.5) + WhiteKernel(noise_level=0.0248)\n",
      "  best_LML: -18.696\n",
      "  mu(x*): 1692.712959 | sigma(x*): 149.611291\n",
      "  exploration_ratio (proxy): 0.081\n",
      "  LML candidates:\n",
      "    - -22.390 :: 1.27**2 * RBF(length_scale=[50, 2.14, 0.219, 0.185]) + WhiteKernel(noise_level=1e-05)\n",
      "    - -19.288 :: 4.04**2 * Matern(length_scale=[24.4, 50, 1.6, 0.986], nu=1.5) + WhiteKernel(noise_level=0.0194)\n",
      "    - -18.696 :: 4.47**2 * Matern(length_scale=[20.2, 50, 1.19, 0.753], nu=2.5) + WhiteKernel(noise_level=0.0248)\n",
      "\n",
      "Function 6 (f6_5d): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 1.78**2 * RBF(length_scale=[0.5, 0.822, 1.32, 1.31, 0.476]) + WhiteKernel(noise_level=5.17e-10)\n",
      "  best_LML: -21.496\n",
      "  mu(x*): -0.043436 | sigma(x*): 0.266409\n",
      "  exploration_ratio (proxy): 0.740\n",
      "  LML candidates:\n",
      "    - -21.496 :: 1.78**2 * RBF(length_scale=[0.5, 0.822, 1.32, 1.31, 0.476]) + WhiteKernel(noise_level=5.17e-10)\n",
      "    - -22.649 :: 2.63**2 * Matern(length_scale=[1.15, 1.95, 2.57, 3.06, 1.6], nu=1.5) + WhiteKernel(noise_level=9.99e-06)\n",
      "    - -22.271 :: 2.1**2 * Matern(length_scale=[0.743, 1.24, 1.88, 1.94, 0.841], nu=2.5) + WhiteKernel(noise_level=9.99e-06)\n",
      "\n",
      "Function 7 (f7_6d): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 1.1**2 * RBF(length_scale=[50, 0.81, 0.0996, 50, 50, 0.275]) + WhiteKernel(noise_level=9.93e-06)\n",
      "  best_LML: -12.997\n",
      "  mu(x*): 1.287534 | sigma(x*): 0.206052\n",
      "  exploration_ratio (proxy): 0.133\n",
      "  LML candidates:\n",
      "    - -12.997 :: 1.1**2 * RBF(length_scale=[50, 0.81, 0.0996, 50, 50, 0.275]) + WhiteKernel(noise_level=9.93e-06)\n",
      "    - -13.699 :: 1.12**2 * Matern(length_scale=[50, 1.26, 0.119, 50, 50, 0.323], nu=1.5) + WhiteKernel(noise_level=9.98e-06)\n",
      "    - -13.410 :: 1.12**2 * Matern(length_scale=[50, 1.04, 0.114, 50, 50, 0.312], nu=2.5) + WhiteKernel(noise_level=9.98e-06)\n",
      "\n",
      "Function 8 (f8_8d): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 6.95**2 * Matern(length_scale=[7.68, 12, 5.88, 14.2, 36.6, 12.5, 8.26, 50], nu=1.5) + WhiteKernel(noise_level=3.77e-10)\n",
      "  best_LML: -3.643\n",
      "  mu(x*): 10.112777 | sigma(x*): 0.245283\n",
      "  exploration_ratio (proxy): 0.024\n",
      "  LML candidates:\n",
      "    - -7.711 :: 1.94**2 * RBF(length_scale=[1.03, 1.48, 0.713, 3.58, 5.66, 9.77, 0.745, 50]) + WhiteKernel(noise_level=1.06e-10)\n",
      "    - -3.643 :: 6.95**2 * Matern(length_scale=[7.68, 12, 5.88, 14.2, 36.6, 12.5, 8.26, 50], nu=1.5) + WhiteKernel(noise_level=3.77e-10)\n",
      "    - -4.064 :: 2.84**2 * Matern(length_scale=[2.12, 3.09, 1.49, 3.7, 10, 50, 2.26, 50], nu=2.5) + WhiteKernel(noise_level=5.99e-11)\n",
      "\n",
      "\n",
      "Saved plots to: C:\\Users\\prasa\\anaconda_projects\\eMeritus\\plots\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "bbo_gp_weekly_generator_dynamic_history_and_plots.py\n",
    "\n",
    "-----------------------\n",
    "✅ Load the fixed historical datasets (points_*/values_*)\n",
    "✅ Loads growing weekly history from JSON (auto)\n",
    "✅ Fits 1 GP per function, auto-selects kernel by max log-marginal-likelihood (LML)\n",
    "✅ Per-function exploration vs exploitation (based on last completed week's performance)\n",
    "✅ Per-function tuning via ξ (xi) for EI/PI or β (beta) for UCB\n",
    "✅ Generates NEXT WEEK inputs in portal format (8 lines)\n",
    "✅ Automatically stores generated NEXT WEEK inputs into JSON (outputs=None until you fill them)\n",
    "✅ Optionally lets you paste outputs immediately (interactive prompt)\n",
    "✅ Saves plots into:\n",
    "    ./plots/function_01/...\n",
    "    ./plots/function_02/...\n",
    "    ...\n",
    "    - 2D: GP posterior mean contour + observed points + next point\n",
    "    - 3D+: PCA scatter (observed points colored by y) + next point\n",
    "    - all: y vs iteration plot\n",
    "✅ Also writes a per-function \"diagnostics.json\" under each function folder\n",
    "\n",
    "IMPORTANT\n",
    "---------\n",
    "1) This script assumes domain is [0,1]^d for all functions.\n",
    "2) Portal constraints: each x_i must start with 0 and be 6 decimals.\n",
    "   -> we clip to [0.0, 0.999999].\n",
    "3) DO NOT use `array([...])` anywhere. Use `np.array([...])`.\n",
    "   (Your NameError came from using `array(...)` without importing it.)\n",
    "4) You can run this weekly:\n",
    "   - Run script → it generates Week N+1 inputs and saves to JSON.\n",
    "   - After you receive outputs, either:\n",
    "       A) Re-run and paste outputs when prompted, OR\n",
    "       B) Edit JSON and fill outputs for that week.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel, ConstantKernel\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import norm\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# ============================================================\n",
    "# WARNING POLICY\n",
    "# ============================================================\n",
    "# You can either:\n",
    "# - silence convergence warnings (default below), OR\n",
    "# - set SHOW_CONVERGENCE_WARNINGS=True to see them.\n",
    "SHOW_CONVERGENCE_WARNINGS = False\n",
    "if not SHOW_CONVERGENCE_WARNINGS:\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "ACQUISITION = \"ei\"          # \"ei\", \"pi\", or \"ucb\"\n",
    "DECIMALS = 6\n",
    "RNG_SEED = 123\n",
    "\n",
    "# Candidate pool for picking next point (larger = better exploration, slower)\n",
    "N_CANDIDATES = 70000\n",
    "\n",
    "# GP settings\n",
    "NOISE_ALPHA = 1e-10\n",
    "USE_AUTO_KERNEL = True\n",
    "\n",
    "# Restarts for kernel optimization\n",
    "RESTARTS_LOW_D = 10     # 2D-3D\n",
    "RESTARTS_MID_D = 6      # 4D-5D\n",
    "RESTARTS_HIGH_D = 2     # 6D-8D\n",
    "\n",
    "# Kernel length-scale bounds (increase upper bound to reduce \"hit upper bound\" warnings)\n",
    "LS_BOUNDS = (1e-3, 50.0)\n",
    "\n",
    "# WhiteKernel noise bounds (increase upper bound if you see \"hit upper bound\" warnings often)\n",
    "NOISE_BOUNDS = (1e-12, 1e-1)\n",
    "\n",
    "# Explore vs exploit decision (maximize)\n",
    "EXPLOIT_TOL_FRAC_OF_RANGE = 0.10  # within 10% of best-so-far range => exploit\n",
    "\n",
    "# Exploration params for acquisition\n",
    "XI_EXPLOIT = 0.001\n",
    "XI_EXPLORE = 0.05\n",
    "BETA_EXPLOIT = 1.0\n",
    "BETA_EXPLORE = 3.0\n",
    "\n",
    "# Persistence (dynamic weekly storage)\n",
    "WEEK_HISTORY_JSON = \"bbo_week_history.json\"\n",
    "AUTO_STORE_GENERATED_WEEK = True\n",
    "\n",
    "# Optional: prompt to paste outputs at runtime (handy right after portal results arrive)\n",
    "PROMPT_FOR_MISSING_OUTPUTS = True\n",
    "\n",
    "# Plots\n",
    "PLOTS_DIR = Path(\"plots\")\n",
    "GRID_RES_2D = 120\n",
    "MAX_POINTS_FOR_PCA_SCATTER = 5000\n",
    "\n",
    "# ============================================================\n",
    "# PORTAL FORMATTING\n",
    "# ============================================================\n",
    "def fmt_query(x: np.ndarray, decimals: int = DECIMALS) -> str:\n",
    "    x = np.asarray(x, dtype=float).reshape(-1)\n",
    "    x = np.clip(x, 0.0, 0.999999)  # must begin with 0.*\n",
    "    return \"-\".join([f\"{v:.{decimals}f}\" for v in x])\n",
    "\n",
    "# ============================================================\n",
    "# ACQUISITION FUNCTIONS\n",
    "# ============================================================\n",
    "def acq_ucb(mu: np.ndarray, sigma: np.ndarray, beta: float) -> np.ndarray:\n",
    "    return mu + beta * sigma\n",
    "\n",
    "def acq_pi(mu: np.ndarray, sigma: np.ndarray, y_best: float, xi: float) -> np.ndarray:\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    z = (mu - y_best - xi) / sigma\n",
    "    return norm.cdf(z)\n",
    "\n",
    "def acq_ei(mu: np.ndarray, sigma: np.ndarray, y_best: float, xi: float) -> np.ndarray:\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    z = imp / sigma\n",
    "    return imp * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "\n",
    "# ============================================================\n",
    "# EXPLORE / EXPLOIT DECISION + PARAM TUNING\n",
    "# ============================================================\n",
    "def decide_mode_maximize(y_last: float, y_hist: np.ndarray, tol_frac: float) -> str:\n",
    "    \"\"\"\n",
    "    If last observed y is close to the best so far (relative to span),\n",
    "    treat it as exploit; otherwise explore.\n",
    "    \"\"\"\n",
    "    y_hist = np.asarray(y_hist, float).reshape(-1)\n",
    "    best = float(np.max(y_hist))\n",
    "    worst = float(np.min(y_hist))\n",
    "    span = max(best - worst, 1e-12)\n",
    "    dist_frac = (best - float(y_last)) / span\n",
    "    return \"exploit\" if dist_frac <= tol_frac else \"explore\"\n",
    "\n",
    "def tune_exploration_params(mode: str, acquisition: str) -> Dict[str, float]:\n",
    "    acquisition = acquisition.lower().strip()\n",
    "    if acquisition in (\"ei\", \"pi\"):\n",
    "        return {\"xi\": XI_EXPLOIT if mode == \"exploit\" else XI_EXPLORE}\n",
    "    if acquisition == \"ucb\":\n",
    "        return {\"beta\": BETA_EXPLOIT if mode == \"exploit\" else BETA_EXPLORE}\n",
    "    raise ValueError(\"ACQUISITION must be one of: ei, pi, ucb\")\n",
    "\n",
    "# ============================================================\n",
    "# KERNEL SELECTION BY LOG MARGINAL LIKELIHOOD (LML)\n",
    "# ============================================================\n",
    "def restarts_for_dim(dim: int) -> int:\n",
    "    if dim <= 3:\n",
    "        return RESTARTS_LOW_D\n",
    "    if dim <= 5:\n",
    "        return RESTARTS_MID_D\n",
    "    return RESTARTS_HIGH_D\n",
    "\n",
    "def make_kernel_pool(dim: int) -> List[Any]:\n",
    "    # Rough initial LS guess: larger for higher dims\n",
    "    ls0 = 0.30 if dim <= 3 else (0.40 if dim <= 5 else 0.60)\n",
    "\n",
    "    base = [\n",
    "        RBF(length_scale=np.ones(dim) * ls0, length_scale_bounds=LS_BOUNDS),\n",
    "        Matern(length_scale=np.ones(dim) * ls0, length_scale_bounds=LS_BOUNDS, nu=1.5),\n",
    "        Matern(length_scale=np.ones(dim) * ls0, length_scale_bounds=LS_BOUNDS, nu=2.5),\n",
    "    ]\n",
    "\n",
    "    pool: List[Any] = []\n",
    "    for bk in base:\n",
    "        pool.append(\n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * bk +\n",
    "            WhiteKernel(noise_level=1e-5, noise_level_bounds=NOISE_BOUNDS)\n",
    "        )\n",
    "    return pool\n",
    "\n",
    "def fit_gp_and_lml(X: np.ndarray, y: np.ndarray, kernel: Any, seed: int, n_restarts: int):\n",
    "    gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=NOISE_ALPHA,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=n_restarts,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    gp.fit(X, y)\n",
    "    lml = float(gp.log_marginal_likelihood(gp.kernel_.theta))\n",
    "    return gp, lml\n",
    "\n",
    "def fit_best_gp_by_lml_with_details(X: np.ndarray, y: np.ndarray, dim: int, seed: int):\n",
    "    X = np.asarray(X, float).reshape(-1, dim)\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "\n",
    "    pool = make_kernel_pool(dim)\n",
    "    n_restarts = restarts_for_dim(dim)\n",
    "\n",
    "    best_gp: Optional[GaussianProcessRegressor] = None\n",
    "    best_lml = -np.inf\n",
    "    best_kernel_str = \"\"\n",
    "    details: List[Tuple[str, float]] = []\n",
    "\n",
    "    for j, kernel in enumerate(pool):\n",
    "        gp, lml = fit_gp_and_lml(X, y, kernel, seed=seed + 17 * j, n_restarts=n_restarts)\n",
    "        kstr = str(gp.kernel_)\n",
    "        details.append((kstr, float(lml)))\n",
    "        if lml > best_lml:\n",
    "            best_lml = float(lml)\n",
    "            best_gp = gp\n",
    "            best_kernel_str = kstr\n",
    "\n",
    "    assert best_gp is not None\n",
    "    return best_gp, best_kernel_str, float(best_lml), details\n",
    "\n",
    "# ============================================================\n",
    "# EXPLORATION RATIO PROXY (for reporting)\n",
    "# ============================================================\n",
    "def exploration_ratio(mu: float, sigma: float, acquisition: str, xi: float, beta: float) -> float:\n",
    "    acquisition = acquisition.lower().strip()\n",
    "    if acquisition == \"ucb\":\n",
    "        return float((beta * sigma) / (abs(mu) + beta * sigma + 1e-12))\n",
    "    return float(sigma / (abs(mu) + sigma + xi + 1e-12))\n",
    "\n",
    "# ============================================================\n",
    "# PROPOSE NEXT POINT\n",
    "# ============================================================\n",
    "def propose_next_point_with_reporting(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    dim: int,\n",
    "    *,\n",
    "    acquisition: str,\n",
    "    xi: float,\n",
    "    beta: float,\n",
    "    seed: int,\n",
    "    n_candidates: int,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if USE_AUTO_KERNEL:\n",
    "        gp, kernel_str, best_lml, lml_details = fit_best_gp_by_lml_with_details(X, y, dim, seed)\n",
    "    else:\n",
    "        kernel = ConstantKernel(1.0, (1e-3, 1e3)) * Matern(\n",
    "            length_scale=np.ones(dim) * 0.35, length_scale_bounds=LS_BOUNDS, nu=2.5\n",
    "        ) + WhiteKernel(1e-5, NOISE_BOUNDS)\n",
    "        gp = GaussianProcessRegressor(\n",
    "            kernel=kernel,\n",
    "            alpha=NOISE_ALPHA,\n",
    "            normalize_y=True,\n",
    "            n_restarts_optimizer=restarts_for_dim(dim),\n",
    "            random_state=seed,\n",
    "        )\n",
    "        gp.fit(X, y)\n",
    "        kernel_str = str(gp.kernel_)\n",
    "        best_lml = float(gp.log_marginal_likelihood(gp.kernel_.theta))\n",
    "        lml_details = [(kernel_str, best_lml)]\n",
    "\n",
    "    Xcand = rng.uniform(0.0, 1.0, size=(n_candidates, dim))\n",
    "    mu, sigma = gp.predict(Xcand, return_std=True)\n",
    "    mu = mu.reshape(-1)\n",
    "    sigma = sigma.reshape(-1)\n",
    "\n",
    "    y_best = float(np.max(y))\n",
    "    a = acquisition.lower().strip()\n",
    "\n",
    "    if a == \"ei\":\n",
    "        score = acq_ei(mu, sigma, y_best=y_best, xi=xi)\n",
    "    elif a == \"pi\":\n",
    "        score = acq_pi(mu, sigma, y_best=y_best, xi=xi)\n",
    "    elif a == \"ucb\":\n",
    "        score = acq_ucb(mu, sigma, beta=beta)\n",
    "    else:\n",
    "        raise ValueError(\"ACQUISITION must be one of: ei, pi, ucb\")\n",
    "\n",
    "    best_idx = int(np.argmax(score))\n",
    "    x_next = Xcand[best_idx]\n",
    "    mu_best = float(mu[best_idx])\n",
    "    sigma_best = float(sigma[best_idx])\n",
    "    ratio = exploration_ratio(mu_best, sigma_best, acquisition, xi, beta)\n",
    "\n",
    "    report = {\n",
    "        \"kernel\": kernel_str,\n",
    "        \"best_lml\": float(best_lml),\n",
    "        \"lml_candidates\": lml_details,\n",
    "        \"mu_at_choice\": mu_best,\n",
    "        \"sigma_at_choice\": sigma_best,\n",
    "        \"exploration_ratio\": ratio,\n",
    "    }\n",
    "    return x_next, fmt_query(x_next), report, gp\n",
    "\n",
    "# ============================================================\n",
    "# PLOTTING\n",
    "# ============================================================\n",
    "def ensure_func_plot_dir(func_idx: int) -> Path:\n",
    "    d = PLOTS_DIR / f\"function_{func_idx:02d}\"\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "def plot_y_over_iterations(func_idx: int, key: str, y: np.ndarray, out_path: Path) -> None:\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "    it = np.arange(1, len(y) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(it, y, marker=\"o\")\n",
    "    plt.axhline(np.max(y), linestyle=\"--\")\n",
    "    plt.title(f\"{key} (Function {func_idx}) - y over iterations\")\n",
    "    plt.xlabel(\"Observation index\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_2d_gp_mean_contour(func_idx: int, key: str, gp: GaussianProcessRegressor,\n",
    "                            X_obs: np.ndarray, y_obs: np.ndarray, x_next: np.ndarray,\n",
    "                            out_path: Path, grid_res: int = GRID_RES_2D) -> None:\n",
    "    xs = np.linspace(0.0, 1.0, grid_res)\n",
    "    ys = np.linspace(0.0, 1.0, grid_res)\n",
    "    X1, X2 = np.meshgrid(xs, ys)\n",
    "    grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "    mu = gp.predict(grid).reshape(grid_res, grid_res)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.contourf(X1, X2, mu, levels=20)\n",
    "    plt.scatter(X_obs[:, 0], X_obs[:, 1], c=y_obs, marker=\"o\")\n",
    "    plt.scatter([x_next[0]], [x_next[1]], marker=\"X\", s=120)\n",
    "    plt.title(f\"{key} (Function {func_idx}) - GP mean (2D)\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def plot_pca_scatter(func_idx: int, key: str, X_obs: np.ndarray, y_obs: np.ndarray, x_next: np.ndarray,\n",
    "                     out_path: Path) -> None:\n",
    "    X_obs = np.asarray(X_obs, float)\n",
    "    y_obs = np.asarray(y_obs, float).reshape(-1)\n",
    "\n",
    "    if X_obs.shape[0] > MAX_POINTS_FOR_PCA_SCATTER:\n",
    "        idx = np.random.default_rng(RNG_SEED + func_idx).choice(\n",
    "            X_obs.shape[0], size=MAX_POINTS_FOR_PCA_SCATTER, replace=False\n",
    "        )\n",
    "        X_plot = X_obs[idx]\n",
    "        y_plot = y_obs[idx]\n",
    "    else:\n",
    "        X_plot, y_plot = X_obs, y_obs\n",
    "\n",
    "    X_stack = np.vstack([X_plot, x_next.reshape(1, -1)])\n",
    "    pca = PCA(n_components=2, random_state=RNG_SEED + func_idx)\n",
    "    Z = pca.fit_transform(X_stack)\n",
    "    Z_obs = Z[:-1]\n",
    "    Z_next = Z[-1]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(Z_obs[:, 0], Z_obs[:, 1], c=y_plot, marker=\"o\")\n",
    "    plt.scatter([Z_next[0]], [Z_next[1]], marker=\"X\", s=120)\n",
    "    plt.title(f\"{key} (Function {func_idx}) - PCA projection\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def write_diagnostics_json(func_dir: Path, diagnostics: dict) -> None:\n",
    "    p = func_dir / \"diagnostics.json\"\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(diagnostics, f, indent=2)\n",
    "\n",
    "# ============================================================\n",
    "# DATA STRUCTURES\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class FunctionDataset:\n",
    "    key: str\n",
    "    dim: int\n",
    "    X: np.ndarray\n",
    "    y: np.ndarray\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.X = np.asarray(self.X, float).reshape(-1, self.dim)\n",
    "        self.y = np.asarray(self.y, float).reshape(-1)\n",
    "        if self.X.shape[0] != self.y.shape[0]:\n",
    "            raise ValueError(f\"{self.key}: X rows != y rows\")\n",
    "\n",
    "    def append(self, x_new: np.ndarray, y_new: float) -> None:\n",
    "        x_new = np.asarray(x_new, float).reshape(1, self.dim)\n",
    "        self.X = np.vstack([self.X, x_new])\n",
    "        self.y = np.concatenate([self.y, [float(y_new)]])\n",
    "\n",
    "# ============================================================\n",
    "# WEEK HISTORY (JSON)\n",
    "# ============================================================\n",
    "def load_week_history(path: str) -> dict:\n",
    "    if not os.path.exists(path):\n",
    "        return {\"weeks\": []}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_week_history(path: str, obj: dict) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def np_to_list(x: np.ndarray) -> list:\n",
    "    return [float(v) for v in np.asarray(x, float).reshape(-1)]\n",
    "\n",
    "def append_generated_week(\n",
    "    hist: dict,\n",
    "    week_index: int,\n",
    "    inputs_list: List[np.ndarray],\n",
    "    portal_lines: List[str],\n",
    "    diagnostics: List[dict],\n",
    ") -> None:\n",
    "    entry = {\n",
    "        \"week\": int(week_index),\n",
    "        \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"inputs\": [np_to_list(x) for x in inputs_list],  # list of 8 vectors\n",
    "        \"outputs\": None,                                 # fill later\n",
    "        \"portal_lines\": portal_lines,\n",
    "        \"diagnostics\": diagnostics,\n",
    "    }\n",
    "    hist[\"weeks\"].append(entry)\n",
    "\n",
    "def find_first_missing_outputs_week(hist: dict) -> Optional[dict]:\n",
    "    for wk in hist.get(\"weeks\", []):\n",
    "        if wk.get(\"inputs\") is not None and wk.get(\"outputs\") is None:\n",
    "            return wk\n",
    "    return None\n",
    "\n",
    "def prompt_user_for_outputs(week_number: int) -> Optional[List[float]]:\n",
    "    print(f\"\\nDetected Week {week_number} exists in JSON but outputs are missing.\")\n",
    "    print(\"If you have outputs now, paste them as 8 comma-separated numbers (or press Enter to skip).\")\n",
    "    raw = input(\"Outputs (8 values): \").strip()\n",
    "    if not raw:\n",
    "        return None\n",
    "    parts = [p.strip() for p in raw.split(\",\") if p.strip()]\n",
    "    if len(parts) != 8:\n",
    "        print(\"❌ Expected exactly 8 values. Skipping output update.\")\n",
    "        return None\n",
    "    try:\n",
    "        vals = [float(v) for v in parts]\n",
    "        return vals\n",
    "    except ValueError:\n",
    "        print(\"❌ Could not parse floats. Skipping output update.\")\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# YOUR FIXED HISTORICAL DATASETS (PASTE/KEEP HERE)\n",
    "# ============================================================\n",
    "# NOTE: This section is exactly where your fixed historical arrays live.\n",
    "# If you already have them, keep them as-is.\n",
    "\n",
    "# 2D DATASET A (tiny values)\n",
    "points_2d_a = np.array([\n",
    "    [0.31940389, 0.76295937],\n",
    "    [0.57432921, 0.87989810],\n",
    "    [0.73102363, 0.73299988],\n",
    "    [0.84035342, 0.26473161],\n",
    "    [0.65011406, 0.68152635],\n",
    "    [0.41043714, 0.14755430],\n",
    "    [0.31269116, 0.07872278],\n",
    "    [0.68341817, 0.86105746],\n",
    "    [0.08250725, 0.40348751],\n",
    "])\n",
    "values_2d_a = np.array([\n",
    "    1.3226770395454077e-79,\n",
    "    1.0330782375230975e-46,\n",
    "    7.710875114502849e-16,\n",
    "    3.341771007676023e-124,\n",
    "    -0.0036060626443634764,\n",
    "    -2.1592490357331095e-54,\n",
    "    -2.0890932702320842e-91,\n",
    "    2.5350011535584046e-40,\n",
    "    3.6067711901420254e-81,\n",
    "])\n",
    "\n",
    "# 2D DATASET B (normal-ish values)\n",
    "points_2d_b = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.77862750],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "])\n",
    "values_2d_b = np.array([\n",
    "    0.5389961189269181,\n",
    "    0.42058623962798264,\n",
    "    -0.06562362443733738,\n",
    "    0.293992912410866,\n",
    "    0.2149645101004509,\n",
    "    0.023105549798190586,\n",
    "    0.24461934400448035,\n",
    "    0.0387490151561584,\n",
    "    -0.013857618149729824,\n",
    "])\n",
    "\n",
    "# 3D DATASET\n",
    "points_3d = np.array([\n",
    "    [0.17152521, 0.34391687, 0.24873720],\n",
    "    [0.24211446, 0.64407427, 0.27243281],\n",
    "    [0.53490572, 0.39850092, 0.17338873],\n",
    "    [0.49258141, 0.61159319, 0.34017639],\n",
    "    [0.13462167, 0.21991724, 0.45820622],\n",
    "    [0.34552327, 0.94135983, 0.26936348],\n",
    "    [0.15183663, 0.43999062, 0.99088187],\n",
    "    [0.64550284, 0.39714294, 0.91977134],\n",
    "    [0.74691195, 0.28419631, 0.22629985],\n",
    "    [0.17047699, 0.69703240, 0.14916943],\n",
    "    [0.22054934, 0.29782524, 0.34355534],\n",
    "    [0.66601366, 0.67198515, 0.24629530],\n",
    "    [0.04680895, 0.23136024, 0.77061759],\n",
    "    [0.60009728, 0.72513573, 0.06608864],\n",
    "])\n",
    "values_3d = np.array([\n",
    "    -0.11212220046256897,\n",
    "    -0.08796286022736445,\n",
    "    -0.11141465429532400,\n",
    "    -0.034835313350078584,\n",
    "    -0.04800758439218157,\n",
    "    -0.11062091307282658,\n",
    "    -0.39892551314630110,\n",
    "    -0.11386851478863991,\n",
    "    -0.13146060864136055,\n",
    "    -0.09418956091057398,\n",
    "    -0.04694740582651916,\n",
    "    -0.10596503573558178,\n",
    "    -0.11804825644688696,\n",
    "    -0.036377828071632486,\n",
    "])\n",
    "\n",
    "# 4D DATASET A (negative)\n",
    "points_4d_a = np.array([\n",
    "    [0.89698105, 0.72562797, 0.17540431, 0.70169437],\n",
    "    [0.88935640, 0.49958786, 0.53926886, 0.50878344],\n",
    "    [0.25094624, 0.03369313, 0.14538002, 0.49493242],\n",
    "    [0.34696206, 0.00625040, 0.76056361, 0.61302356],\n",
    "    [0.12487118, 0.12977019, 0.38440048, 0.28707610],\n",
    "    [0.80130271, 0.50023109, 0.70664456, 0.19510284],\n",
    "    [0.24770826, 0.06044543, 0.04218635, 0.44132425],\n",
    "    [0.74670224, 0.75709150, 0.36935306, 0.20656628],\n",
    "    [0.40066503, 0.07257425, 0.88676825, 0.24384229],\n",
    "    [0.62607060, 0.58675126, 0.43880578, 0.77885769],\n",
    "    [0.95713529, 0.59764438, 0.76611385, 0.77620991],\n",
    "    [0.73281243, 0.14524998, 0.47681272, 0.13336573],\n",
    "    [0.65511548, 0.07239183, 0.68715175, 0.08151656],\n",
    "    [0.21973443, 0.83203134, 0.48286416, 0.08256923],\n",
    "    [0.48859419, 0.21196510, 0.93917791, 0.37619173],\n",
    "    [0.16713049, 0.87655456, 0.21723954, 0.95980098],\n",
    "    [0.21691119, 0.16608583, 0.24137226, 0.77006248],\n",
    "    [0.38748784, 0.80453226, 0.75179548, 0.72382744],\n",
    "    [0.98562189, 0.66693268, 0.15678328, 0.85653480],\n",
    "    [0.03782483, 0.66485335, 0.16198218, 0.25392378],\n",
    "    [0.68348638, 0.90277010, 0.33541983, 0.99948256],\n",
    "    [0.17034731, 0.75695908, 0.27652049, 0.53123150],\n",
    "    [0.85965692, 0.91959232, 0.20613873, 0.09779683],\n",
    "    [0.28213837, 0.50598691, 0.53053084, 0.09630162],\n",
    "    [0.32607578, 0.47236690, 0.45319200, 0.10588734],\n",
    "    [0.94838936, 0.89451301, 0.85163782, 0.55219629],\n",
    "    [0.66495539, 0.04656628, 0.11677747, 0.79371778],\n",
    "    [0.57776561, 0.42877174, 0.42582587, 0.24900741],\n",
    "    [0.73861301, 0.48210263, 0.70936644, 0.50397001],\n",
    "])\n",
    "values_4d_a = np.array([\n",
    "    -22.108287785435817,\n",
    "    -14.601396631953161,\n",
    "    -11.699932463834426,\n",
    "    -16.053765110568296,\n",
    "    -10.069633426012889,\n",
    "    -15.487082537755288,\n",
    "    -12.681684976815650,\n",
    "    -16.026399768983520,\n",
    "    -17.049234647535723,\n",
    "    -12.741765988316185,\n",
    "    -27.316396356142608,\n",
    "    -13.527648872277506,\n",
    "    -16.679115197479913,\n",
    "    -16.507158564282340,\n",
    "    -17.817999338829490,\n",
    "    -26.561820829779602,\n",
    "    -12.758324216781741,\n",
    "    -19.441557624451722,\n",
    "    -28.903273673833770,\n",
    "    -13.702746938161251,\n",
    "    -29.427091401989347,\n",
    "    -11.565741989583191,\n",
    "    -26.857786437773637,\n",
    "    -7.9667753510303925,\n",
    "    -6.702089254839066,\n",
    "    -32.625660215962455,\n",
    "    -19.989497926795560,\n",
    "    -4.025542281908162,\n",
    "    -13.122782331852594,\n",
    "])\n",
    "\n",
    "# 4D DATASET B (positive)\n",
    "points_4d_b = np.array([\n",
    "    [0.19144708, 0.03819337, 0.60741781, 0.41458414],\n",
    "    [0.75865295, 0.53651774, 0.65600038, 0.36034155],\n",
    "    [0.43834987, 0.80433970, 0.21024527, 0.15129482],\n",
    "    [0.70605083, 0.53419196, 0.26424335, 0.48208755],\n",
    "    [0.83647799, 0.19360965, 0.66389270, 0.78564888],\n",
    "    [0.68343225, 0.11866264, 0.82904591, 0.56757661],\n",
    "    [0.55362148, 0.66734998, 0.32380582, 0.81486975],\n",
    "    [0.35235627, 0.32224153, 0.11697937, 0.47311252],\n",
    "    [0.15378571, 0.72938169, 0.42259844, 0.44307417],\n",
    "    [0.46344227, 0.63002451, 0.10790646, 0.95764390],\n",
    "    [0.67749115, 0.35850951, 0.47959222, 0.07288048],\n",
    "    [0.58397341, 0.14724265, 0.34809746, 0.42861465],\n",
    "    [0.30688872, 0.31687813, 0.62263448, 0.09539906],\n",
    "    [0.51114177, 0.81795700, 0.72871042, 0.11235362],\n",
    "    [0.43893338, 0.77409176, 0.37816709, 0.93369621],\n",
    "    [0.22418902, 0.84648049, 0.87948418, 0.87851568],\n",
    "    [0.72526172, 0.47987049, 0.08894684, 0.75976022],\n",
    "    [0.35548161, 0.63961937, 0.41761768, 0.12260384],\n",
    "    [0.11987923, 0.86254031, 0.64333133, 0.84980383],\n",
    "])\n",
    "values_4d_b = np.array([\n",
    "    64.443439863301,\n",
    "    18.30137959857266,\n",
    "    0.1129397953712203,\n",
    "    4.210898128938665,\n",
    "    258.3705254462536,\n",
    "    78.43438888779464,\n",
    "    57.57153693261287,\n",
    "    109.5718755614928,\n",
    "    8.847991759070865,\n",
    "    233.22361017104996,\n",
    "    24.423088313942344,\n",
    "    64.42014681963983,\n",
    "    63.47671578508436,\n",
    "    79.72912992694343,\n",
    "    355.8068177560159,\n",
    "    1088.8596181962705,\n",
    "    28.866751637393822,\n",
    "    45.181570346703786,\n",
    "    431.6127567592104,\n",
    "])\n",
    "\n",
    "# 5D DATASET\n",
    "points_5d = np.array([\n",
    "    [0.72818610, 0.15469257, 0.73255167, 0.69399651, 0.05640131],\n",
    "    [0.24238435, 0.84409997, 0.57780910, 0.67902128, 0.50195289],\n",
    "    [0.72952261, 0.74810620, 0.67977464, 0.35655228, 0.67105368],\n",
    "    [0.77062024, 0.11440374, 0.04677993, 0.64832428, 0.27354905],\n",
    "    [0.61881230, 0.33180214, 0.18728787, 0.75623847, 0.32883480],\n",
    "    [0.78495809, 0.91068235, 0.70812010, 0.95922543, 0.00491150],\n",
    "    [0.14511079, 0.89668460, 0.89632223, 0.72627154, 0.23627199],\n",
    "    [0.94506907, 0.28845905, 0.97880576, 0.96165559, 0.59801594],\n",
    "    [0.12572016, 0.86272469, 0.02854433, 0.24660527, 0.75120624],\n",
    "    [0.75759436, 0.35583141, 0.01652290, 0.43420720, 0.11243304],\n",
    "    [0.53679690, 0.30878091, 0.41187929, 0.38822518, 0.52252830],\n",
    "    [0.95773967, 0.23566857, 0.09914585, 0.15680593, 0.07131737],\n",
    "    [0.62930790, 0.80348368, 0.81140844, 0.04561319, 0.11062446],\n",
    "    [0.02173531, 0.42808424, 0.83593944, 0.48948866, 0.51108173],\n",
    "    [0.43934426, 0.69892383, 0.42682022, 0.10947609, 0.87788847],\n",
    "    [0.25890557, 0.79367771, 0.64211390, 0.19667346, 0.59310318],\n",
    "    [0.43216593, 0.71561781, 0.34181910, 0.70499988, 0.61496184],\n",
    "    [0.78287982, 0.53633586, 0.44328356, 0.85969983, 0.01032599],\n",
    "    [0.92177620, 0.93187122, 0.41487637, 0.59505727, 0.73562569],\n",
    "])\n",
    "values_5d = np.array([\n",
    "    -0.7142649478202404,\n",
    "    -1.2099552446764819,\n",
    "    -1.6721999396105658,\n",
    "    -1.5360577085694833,\n",
    "    -0.8292365522578722,\n",
    "    -1.2470489267904978,\n",
    "    -1.2337863805718483,\n",
    "    -1.6943434420704928,\n",
    "    -2.5711696316081234,\n",
    "    -1.3091163528236960,\n",
    "    -1.1447848512705794,\n",
    "    -1.9126771431925136,\n",
    "    -1.6228389517771730,\n",
    "    -1.3566821093823407,\n",
    "    -2.0184253993747820,\n",
    "    -1.7025578405650035,\n",
    "    -1.2942469649550403,\n",
    "    -0.9357565553342914,\n",
    "    -2.1557677641786004,\n",
    "])\n",
    "\n",
    "# 6D DATASET\n",
    "points_6d = np.array([\n",
    "    [0.27262382, 0.32449536, 0.89710881, 0.83295115, 0.15406269, 0.79586362],\n",
    "    [0.54300258, 0.92469390, 0.34156746, 0.64648585, 0.71844033, 0.34313266],\n",
    "    [0.09083225, 0.66152938, 0.06593091, 0.25857701, 0.96345285, 0.64026540],\n",
    "    [0.11886697, 0.61505494, 0.90581639, 0.85530030, 0.41363143, 0.58523563],\n",
    "    [0.63021764, 0.83809690, 0.68001305, 0.73189509, 0.52673671, 0.34842921],\n",
    "    [0.76491917, 0.25588292, 0.60908422, 0.21807904, 0.32294277, 0.09579366],\n",
    "    [0.05789554, 0.49167222, 0.24742222, 0.21811844, 0.42042833, 0.73096984],\n",
    "    [0.19525188, 0.07922665, 0.55458046, 0.17056682, 0.01494418, 0.10703171],\n",
    "    [0.64230298, 0.83687455, 0.02179269, 0.10148801, 0.68307083, 0.69241640],\n",
    "])\n",
    "values_6d = np.array([\n",
    "    0.6044326958745716,\n",
    "    0.5627530668655433,\n",
    "    0.007503236678049401,\n",
    "    0.06142430250355775,\n",
    "    0.27304680126759867,\n",
    "    0.08374657232015563,\n",
    "    1.3649683044991994,\n",
    "    0.09264495494793601,\n",
    "    0.017869598722495817,\n",
    "])\n",
    "\n",
    "# 8D DATASET\n",
    "points_8d = np.array([\n",
    "    [0.60499445,0.29221502,0.90845275,0.35550624,0.20166872,0.57533801,0.31031095,0.73428138],\n",
    "    [0.17800696,0.56622265,0.99486184,0.21032501,0.32015266,0.70790879,0.63538449,0.10713163],\n",
    "    [0.00907698,0.81162615,0.52052036,0.07568668,0.26511183,0.09165169,0.59241515,0.36732026],\n",
    "    [0.50602816,0.65373012,0.36341078,0.17798105,0.09372830,0.19742533,0.75582690,0.29247234],\n",
    "    [0.35990926,0.24907568,0.49599717,0.70921498,0.11498719,0.28920692,0.55729515,0.59388173],\n",
    "    [0.77881834,0.00341950,0.33798313,0.51952778,0.82090699,0.53724669,0.55134710,0.66003209],\n",
    "    [0.90864932,0.06224970,0.23825955,0.76660355,0.13233596,0.99024381,0.68806782,0.74249594],\n",
    "    [0.58637144,0.88073573,0.74502075,0.54603485,0.00964888,0.74899176,0.23090707,0.09791562],\n",
    "    [0.76113733,0.85467239,0.38212433,0.33735198,0.68970832,0.30985305,0.63137968,0.04195607],\n",
    "    [0.98493320,0.69950626,0.99888550,0.18014846,0.58014315,0.23108719,0.49082694,0.31368272],\n",
    "    [0.11207131,0.43773566,0.59659878,0.59277563,0.22698177,0.41010452,0.92123758,0.67475276],\n",
    "    [0.79188751,0.57619134,0.69452836,0.28342378,0.13675546,0.27916186,0.84276726,0.62532792],\n",
    "    [0.14355030,0.93741452,0.23232482,0.00904349,0.41457893,0.40932517,0.55377852,0.20584080],\n",
    "    [0.76991655,0.45875909,0.55900044,0.69460444,0.50319902,0.72834638,0.78425353,0.66313109],\n",
    "    [0.05644741,0.06595555,0.02292868,0.03878647,0.40393544,0.80105533,0.48830701,0.89308498],\n",
    "    [0.86243745,0.48273382,0.28186940,0.54410223,0.88749026,0.38265469,0.60190199,0.47646169],\n",
    "    [0.35151190,0.59006494,0.90943630,0.67840835,0.21282566,0.08846038,0.41015300,0.19572429],\n",
    "    [0.73590364,0.03461189,0.72803027,0.14742652,0.29574314,0.44511731,0.97517969,0.37433978],\n",
    "    [0.68029397,0.25510465,0.86218799,0.13439582,0.32632920,0.28790687,0.43501048,0.36420013],\n",
    "    [0.04432925,0.01358149,0.25819824,0.57764416,0.05127992,0.15856307,0.59103012,0.07795293],\n",
    "    [0.77834548,0.75114565,0.31414221,0.90298577,0.33538166,0.38632267,0.74897249,0.98875510],\n",
    "    [0.89888711,0.52364170,0.87678325,0.21869645,0.90026089,0.28276624,0.91107791,0.47239822],\n",
    "    [0.14512029,0.11932754,0.42088822,0.38760861,0.15542283,0.87517163,0.51055967,0.72861058],\n",
    "    [0.33895442,0.56693202,0.37675110,0.09891573,0.65945169,0.24554809,0.76248278,0.73215347],\n",
    "    [0.17615002,0.29396143,0.97567997,0.79393631,0.92340076,0.03084229,0.80325452,0.59589758],\n",
    "    [0.02894663,0.02827906,0.48137155,0.61317460,0.67266045,0.02211341,0.60148330,0.52488505],\n",
    "    [0.19263987,0.63067728,0.41679584,0.49052929,0.79608602,0.65456706,0.27624119,0.29551759],\n",
    "    [0.94318502,0.21885062,0.72118408,0.42459707,0.98690200,0.53518298,0.71474318,0.96009372],\n",
    "    [0.53272140,0.83369260,0.07139900,0.11681148,0.73069311,0.93737559,0.86650798,0.12790200],\n",
    "    [0.44709584,0.84395253,0.72954612,0.63915138,0.40928714,0.13264569,0.03590888,0.44683847],\n",
    "    [0.38222497,0.55713584,0.85310163,0.33379569,0.26572127,0.48087292,0.23764706,0.76863196],\n",
    "    [0.53281953,0.86230848,0.53826712,0.04944293,0.71970119,0.90670590,0.10823094,0.52534791],\n",
    "    [0.39486519,0.33180167,0.74075430,0.69786172,0.73740444,0.78377681,0.25449546,0.87114551],\n",
    "    [0.98594539,0.87305363,0.07039262,0.05358729,0.73415296,0.52025852,0.81104004,0.10336036],\n",
    "    [0.96457339,0.97397979,0.66375335,0.66221599,0.67312167,0.90523762,0.45887462,0.56091750],\n",
    "    [0.47207071,0.16820264,0.08642757,0.45265551,0.48061922,0.62243949,0.92897446,0.11253627],\n",
    "    [0.85600695,0.63889370,0.32619202,0.66850311,0.24029837,0.21029889,0.16754636,0.96358986],\n",
    "    [0.81003174,0.63504604,0.26954758,0.86960534,0.66192159,0.25225873,0.76567003,0.89054867],\n",
    "    [0.79625252,0.00703653,0.35569738,0.48756605,0.74051962,0.70665010,0.99291449,0.38173437],\n",
    "])\n",
    "values_8d = np.array([\n",
    "    7.398721101163708,\n",
    "    7.005227361900734,\n",
    "    8.45948161622808,\n",
    "    8.284007811285548,\n",
    "    8.606116791392116,\n",
    "    8.541747923679363,\n",
    "    7.327434575740623,\n",
    "    7.299872046566419,\n",
    "    7.957874742347002,\n",
    "    5.5921933895401965,\n",
    "    7.854540990501387,\n",
    "    6.791985783133633,\n",
    "    8.976554022457023,\n",
    "    7.3790829035972365,\n",
    "    9.598482002566342,\n",
    "    8.159983191736115,\n",
    "    7.13162396619294,\n",
    "    6.767962534878629,\n",
    "    7.433744072022712,\n",
    "    9.013075145673822,\n",
    "    7.310893815253165,\n",
    "    5.841067313187262,\n",
    "    9.141639493309754,\n",
    "    8.817558441363609,\n",
    "    6.451943125106222,\n",
    "    8.83074504574746,\n",
    "    9.34427428080805,\n",
    "    6.887846394035938,\n",
    "    8.042212541982503,\n",
    "    7.692368045766445,\n",
    "    7.923758772464366,\n",
    "    8.42175923792568,\n",
    "    8.27806239964175,\n",
    "    7.113457163948368,\n",
    "    6.402588414582601,\n",
    "    8.472936316651243,\n",
    "    7.977684585372973,\n",
    "    7.460872194740431,\n",
    "    7.436593526746213,\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# OPTIONAL: SEED WEEK1/WEEK2 INTO JSON (ONLY IF JSON IS EMPTY)\n",
    "# ============================================================\n",
    "# If you already have Week 1 and Week 2 inputs/outputs and want the script to\n",
    "# initialize JSON automatically, keep these blocks. Otherwise, you can delete.\n",
    "#\n",
    "# IMPORTANT: Use np.array([...]) not array([...]) to avoid NameError.\n",
    "\n",
    "SEED_WEEKS_IF_JSON_EMPTY = True\n",
    "\n",
    "seed_week1_inputs = [\n",
    "    np.array([0.372451, 0.684219]),\n",
    "    np.array([0.815624, 0.243907]),\n",
    "    np.array([0.214578, 0.739215, 0.563482]),\n",
    "    np.array([0.691245, 0.182734, 0.534817, 0.408263]),\n",
    "    np.array([0.456182, 0.827364, 0.319547, 0.672415]),\n",
    "    np.array([0.238415, 0.564738, 0.792164, 0.413826, 0.689541]),\n",
    "    np.array([0.127394, 0.458216, 0.839275, 0.364182, 0.592736, 0.715204]),\n",
    "    np.array([0.091284, 0.376452, 0.648219, 0.823615, 0.214739, 0.587341, 0.732916, 0.459128]),\n",
    "]\n",
    "seed_week1_outputs = [\n",
    "    float(1.5748453958061012e-48),\n",
    "    float(0.18039410845450976),\n",
    "    float(-0.03855585192956583),\n",
    "    float(-8.961029494112594),\n",
    "    float(49.85674062082695),\n",
    "    float(-1.5130754270634885),\n",
    "    float(0.4692517257441858),\n",
    "    float(7.9402805027841),\n",
    "]\n",
    "\n",
    "seed_week2_inputs = [\n",
    "    np.array([0.263232, 0.692120]),\n",
    "    np.array([0.999999, 0.310918]),\n",
    "    np.array([0.171156, 0.820335, 0.517707]),\n",
    "    np.array([0.757035, 0.095945, 0.402324, 0.338791]),\n",
    "    np.array([0.310629, 0.834492, 0.396231, 0.799219]),\n",
    "    np.array([0.203018, 0.547341, 0.773500, 0.466517, 0.605858]),\n",
    "    np.array([0.000000, 0.578647, 0.913483, 0.367752, 0.528534, 0.777934]),\n",
    "    np.array([0.094269, 0.433556, 0.540599, 0.814786, 0.194082, 0.529488, 0.725916, 0.380393]),\n",
    "]\n",
    "seed_week2_outputs = [\n",
    "    float(-8.412448709899239e-70),\n",
    "    float(0.10235357020556336),\n",
    "    float(-0.03061042303613871),\n",
    "    float(-12.209283145814855),\n",
    "    float(151.27449679067803),\n",
    "    float(-1.3242461523900468),\n",
    "    float(0.3975173339469103),\n",
    "    float(8.2293794088801),\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "def main() -> None:\n",
    "    # Ensure plots dir exists\n",
    "    PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load week history\n",
    "    week_hist = load_week_history(WEEK_HISTORY_JSON)\n",
    "\n",
    "    # Seed Week1/Week2 if JSON is empty (optional convenience)\n",
    "    if SEED_WEEKS_IF_JSON_EMPTY and len(week_hist.get(\"weeks\", [])) == 0:\n",
    "        week_hist[\"weeks\"] = []\n",
    "        week_hist[\"weeks\"].append({\n",
    "            \"week\": 1,\n",
    "            \"generated_at\": \"seeded\",\n",
    "            \"inputs\": [np_to_list(x) for x in seed_week1_inputs],\n",
    "            \"outputs\": seed_week1_outputs,\n",
    "            \"portal_lines\": [fmt_query(x) for x in seed_week1_inputs],\n",
    "            \"diagnostics\": [],\n",
    "        })\n",
    "        week_hist[\"weeks\"].append({\n",
    "            \"week\": 2,\n",
    "            \"generated_at\": \"seeded\",\n",
    "            \"inputs\": [np_to_list(x) for x in seed_week2_inputs],\n",
    "            \"outputs\": seed_week2_outputs,\n",
    "            \"portal_lines\": [fmt_query(x) for x in seed_week2_inputs],\n",
    "            \"diagnostics\": [],\n",
    "        })\n",
    "        save_week_history(WEEK_HISTORY_JSON, week_hist)\n",
    "        print(f\"Seeded Week 1 & 2 into {WEEK_HISTORY_JSON}\\n\")\n",
    "\n",
    "    # If there is a week with inputs but missing outputs, optionally prompt user\n",
    "    if PROMPT_FOR_MISSING_OUTPUTS:\n",
    "        missing = find_first_missing_outputs_week(week_hist)\n",
    "        if missing is not None:\n",
    "            wk_num = int(missing[\"week\"])\n",
    "            outs = prompt_user_for_outputs(wk_num)\n",
    "            if outs is not None:\n",
    "                missing[\"outputs\"] = outs\n",
    "                save_week_history(WEEK_HISTORY_JSON, week_hist)\n",
    "                print(f\"✅ Saved Week {wk_num} outputs into {WEEK_HISTORY_JSON}\\n\")\n",
    "\n",
    "    # Build per-function datasets from historical data\n",
    "    funcs = [\n",
    "        FunctionDataset(\"f1_2d_a\", 2, points_2d_a, values_2d_a),\n",
    "        FunctionDataset(\"f2_2d_b\", 2, points_2d_b, values_2d_b),\n",
    "        FunctionDataset(\"f3_3d\",   3, points_3d,   values_3d),\n",
    "        FunctionDataset(\"f4_4d_a\", 4, points_4d_a, values_4d_a),\n",
    "        FunctionDataset(\"f5_4d_b\", 4, points_4d_b, values_4d_b),\n",
    "        FunctionDataset(\"f6_5d\",   5, points_5d,   values_5d),\n",
    "        FunctionDataset(\"f7_6d\",   6, points_6d,   values_6d),\n",
    "        FunctionDataset(\"f8_8d\",   8, points_8d,   values_8d),\n",
    "    ]\n",
    "\n",
    "    # Append all completed weeks (inputs+outputs) from JSON to the GP training data\n",
    "    completed_weeks = []\n",
    "    for wk in week_hist.get(\"weeks\", []):\n",
    "        if wk.get(\"outputs\") is None:\n",
    "            continue\n",
    "        completed_weeks.append(wk)\n",
    "\n",
    "        wk_inputs = wk[\"inputs\"]   # list of 8 vectors\n",
    "        wk_outputs = wk[\"outputs\"] # list of 8 floats\n",
    "        if len(wk_inputs) != 8 or len(wk_outputs) != 8:\n",
    "            raise RuntimeError(f\"Week {wk.get('week')} in JSON must have 8 inputs and 8 outputs.\")\n",
    "\n",
    "        for i, f in enumerate(funcs):\n",
    "            f.append(np.array(wk_inputs[i], dtype=float), float(wk_outputs[i]))\n",
    "\n",
    "    if len(completed_weeks) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No completed weeks (inputs+outputs) found in JSON. \"\n",
    "            \"Either seed Week1/Week2 or add weeks with outputs.\"\n",
    "        )\n",
    "\n",
    "    last_completed_week = completed_weeks[-1]\n",
    "    last_week_outputs = np.asarray(last_completed_week[\"outputs\"], float).reshape(-1)\n",
    "\n",
    "    # Determine next week number\n",
    "    existing_weeks = [int(w.get(\"week\", 0)) for w in week_hist.get(\"weeks\", [])]\n",
    "    next_week_number = (max(existing_weeks) + 1) if existing_weeks else 1\n",
    "\n",
    "    print(f\"=== Next WEEK {next_week_number} QUERIES (PORTAL FORMAT) ===\")\n",
    "\n",
    "    results_for_debug = []\n",
    "    next_points: List[np.ndarray] = []\n",
    "    portal_lines: List[str] = []\n",
    "\n",
    "    # Generate one next query per function\n",
    "    for func_idx, f in enumerate(funcs, start=1):\n",
    "        # Explore/exploit decision based on last completed week's output for this function\n",
    "        mode = decide_mode_maximize(\n",
    "            y_last=float(last_week_outputs[func_idx - 1]),\n",
    "            y_hist=f.y,\n",
    "            tol_frac=EXPLOIT_TOL_FRAC_OF_RANGE,\n",
    "        )\n",
    "        tuned = tune_exploration_params(mode, ACQUISITION)\n",
    "        xi = float(tuned.get(\"xi\", XI_EXPLORE))\n",
    "        beta = float(tuned.get(\"beta\", BETA_EXPLORE))\n",
    "\n",
    "        x_next, portal_line, report, gp = propose_next_point_with_reporting(\n",
    "            f.X, f.y, f.dim,\n",
    "            acquisition=ACQUISITION,\n",
    "            xi=xi,\n",
    "            beta=beta,\n",
    "            seed=RNG_SEED + 31 * func_idx,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "        )\n",
    "\n",
    "        print(portal_line)\n",
    "        portal_lines.append(portal_line)\n",
    "        next_points.append(x_next)\n",
    "\n",
    "        results_for_debug.append({\n",
    "            \"function_index\": func_idx,\n",
    "            \"function_key\": f.key,\n",
    "            \"dim\": f.dim,\n",
    "            \"mode\": mode,\n",
    "            \"acquisition\": ACQUISITION,\n",
    "            \"xi\": xi,\n",
    "            \"beta\": beta,\n",
    "            \"kernel\": report[\"kernel\"],\n",
    "            \"best_lml\": report[\"best_lml\"],\n",
    "            \"mu_at_choice\": report[\"mu_at_choice\"],\n",
    "            \"sigma_at_choice\": report[\"sigma_at_choice\"],\n",
    "            \"exploration_ratio\": report[\"exploration_ratio\"],\n",
    "            \"lml_candidates\": [\n",
    "                {\"kernel\": kstr, \"lml\": float(lml)} for (kstr, lml) in report[\"lml_candidates\"]\n",
    "            ],\n",
    "            \"x_next\": np_to_list(x_next),\n",
    "        })\n",
    "\n",
    "        # --- plots per function in separate folder ---\n",
    "        func_dir = ensure_func_plot_dir(func_idx)\n",
    "\n",
    "        # y over iterations\n",
    "        plot_y_over_iterations(\n",
    "            func_idx, f.key, f.y,\n",
    "            func_dir / f\"y_over_iters.png\"\n",
    "        )\n",
    "\n",
    "        # 2D vs PCA plot\n",
    "        if f.dim == 2:\n",
    "            plot_2d_gp_mean_contour(\n",
    "                func_idx, f.key, gp, f.X, f.y, x_next,\n",
    "                func_dir / f\"gp_mean_contour_2d.png\"\n",
    "            )\n",
    "        else:\n",
    "            plot_pca_scatter(\n",
    "                func_idx, f.key, f.X, f.y, x_next,\n",
    "                func_dir / f\"pca_scatter.png\"\n",
    "            )\n",
    "\n",
    "        # diagnostics.json per function\n",
    "        write_diagnostics_json(func_dir, results_for_debug[-1])\n",
    "\n",
    "    # Print diagnostics summary in console (optional but useful)\n",
    "    print(\"\\n=== DIAGNOSTICS (kernel / xi-beta / explore-exploit) ===\\n\")\n",
    "    for d in results_for_debug:\n",
    "        print(\n",
    "            f\"Function {d['function_index']} ({d['function_key']}): {d['mode'].upper()} | \"\n",
    "            f\"acquisition={d['acquisition'].upper()} | xi={d['xi']:.6f} | beta={d['beta']:.3f}\\n\"\n",
    "            f\"  chosen_kernel: {d['kernel']}\\n\"\n",
    "            f\"  best_LML: {d['best_lml']:.3f}\\n\"\n",
    "            f\"  mu(x*): {d['mu_at_choice']:.6f} | sigma(x*): {d['sigma_at_choice']:.6f}\\n\"\n",
    "            f\"  exploration_ratio (proxy): {d['exploration_ratio']:.3f}\\n\"\n",
    "        )\n",
    "\n",
    "    # Auto-store generated week inputs into JSON\n",
    "    if AUTO_STORE_GENERATED_WEEK:\n",
    "        append_generated_week(\n",
    "            week_hist,\n",
    "            week_index=next_week_number,\n",
    "            inputs_list=next_points,\n",
    "            portal_lines=portal_lines,\n",
    "            diagnostics=results_for_debug,\n",
    "        )\n",
    "        save_week_history(WEEK_HISTORY_JSON, week_hist)\n",
    "        print(f\"✅ Saved generated Week {next_week_number} inputs to: {WEEK_HISTORY_JSON}\")\n",
    "\n",
    "    print(f\"\\nSaved plots to: {PLOTS_DIR.resolve()}\")\n",
    "    print(\"Next step:\")\n",
    "    print(f\"  - Submit the 8 portal lines above for Week {next_week_number}.\")\n",
    "    print(f\"  - When outputs arrive, either re-run and paste them when prompted,\")\n",
    "    print(f\"    or edit {WEEK_HISTORY_JSON} and fill the 'outputs' list for that week.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9271d5-8f2f-498c-9f83-027aeb976e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
