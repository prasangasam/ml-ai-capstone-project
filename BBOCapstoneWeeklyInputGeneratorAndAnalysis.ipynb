{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e9271d5-8f2f-498c-9f83-027aeb976e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.10.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Next WEEK 5 QUERIES (PORTAL FORMAT) ===\n",
      "0.804537-0.537328\n",
      "0.658368-0.997372\n",
      "0.801681-0.863251-0.481611\n",
      "0.377690-0.412490-0.408035-0.432458\n",
      "0.846177-0.998305-0.997510-0.892575\n",
      "0.427255-0.500377-0.374352-0.971439-0.241657\n",
      "0.315573-0.394539-0.256298-0.196140-0.834450-0.752520\n",
      "0.095926-0.169300-0.093217-0.115986-0.902777-0.374681-0.213161-0.359900\n",
      "\n",
      "=== DIAGNOSTICS (kernel / xi-beta / explore-exploit) ===\n",
      "\n",
      "Function 1 (f1_2d_a): EXPLOIT | acquisition=EI | xi=0.001000 | beta=3.000\n",
      "  chosen_kernel: 1.02**2 * RBF(length_scale=[0.0174, 50]) + WhiteKernel(noise_level=8.6e-12)\n",
      "  best_LML: -17.459\n",
      "  mu(x*): -0.000230 | sigma(x*): 0.000969\n",
      "  exploration_ratio (proxy): 0.441\n",
      "  LML candidates:\n",
      "    - -17.459 :: 1.02**2 * RBF(length_scale=[0.0174, 50]) + WhiteKernel(noise_level=8.6e-12)\n",
      "    - -17.833 :: 1.02**2 * Matern(length_scale=[0.019, 50], nu=1.5) + WhiteKernel(noise_level=3.27e-11)\n",
      "    - -17.682 :: 1.03**2 * Matern(length_scale=[0.0189, 50], nu=2.5) + WhiteKernel(noise_level=5.64e-10)\n",
      "\n",
      "Function 2 (f2_2d_b): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 1.01**2 * RBF(length_scale=[0.0499, 50]) + WhiteKernel(noise_level=0.0198)\n",
      "  best_LML: -14.212\n",
      "  mu(x*): 0.521071 | sigma(x*): 0.043433\n",
      "  exploration_ratio (proxy): 0.071\n",
      "  LML candidates:\n",
      "    - -14.212 :: 1.01**2 * RBF(length_scale=[0.0499, 50]) + WhiteKernel(noise_level=0.0198)\n",
      "    - -14.876 :: 1.01**2 * Matern(length_scale=[0.0607, 50], nu=1.5) + WhiteKernel(noise_level=0.0212)\n",
      "    - -14.617 :: 1.01**2 * Matern(length_scale=[0.0571, 50], nu=2.5) + WhiteKernel(noise_level=0.021)\n",
      "\n",
      "Function 3 (f3_3d): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 1.42**2 * RBF(length_scale=[0.523, 50, 0.145]) + WhiteKernel(noise_level=0.0214)\n",
      "  best_LML: -17.328\n",
      "  mu(x*): -0.001021 | sigma(x*): 0.077072\n",
      "  exploration_ratio (proxy): 0.602\n",
      "  LML candidates:\n",
      "    - -17.328 :: 1.42**2 * RBF(length_scale=[0.523, 50, 0.145]) + WhiteKernel(noise_level=0.0214)\n",
      "    - -18.171 :: 1.58**2 * Matern(length_scale=[50, 50, 0.129], nu=1.5) + WhiteKernel(noise_level=0.0144)\n",
      "    - -17.836 :: 1.64**2 * Matern(length_scale=[0.813, 50, 0.219], nu=2.5) + WhiteKernel(noise_level=0.0192)\n",
      "\n",
      "Function 4 (f4_4d_a): EXPLOIT | acquisition=EI | xi=0.001000 | beta=3.000\n",
      "  chosen_kernel: 3.33**2 * Matern(length_scale=[1.61, 1.56, 1.64, 1.53], nu=2.5) + WhiteKernel(noise_level=0.000774)\n",
      "  best_LML: -15.383\n",
      "  mu(x*): 0.320062 | sigma(x*): 0.450938\n",
      "  exploration_ratio (proxy): 0.584\n",
      "  LML candidates:\n",
      "    - -16.045 :: 1.79**2 * RBF(length_scale=[0.701, 0.682, 0.729, 0.65]) + WhiteKernel(noise_level=0.00111)\n",
      "    - -16.909 :: 5.29**2 * Matern(length_scale=[3.54, 3.33, 3.5, 3.37], nu=1.5) + WhiteKernel(noise_level=0.000144)\n",
      "    - -15.383 :: 3.33**2 * Matern(length_scale=[1.61, 1.56, 1.64, 1.53], nu=2.5) + WhiteKernel(noise_level=0.000774)\n",
      "\n",
      "Function 5 (f5_4d_b): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 4.07**2 * Matern(length_scale=[50, 3.96, 0.505, 12.4], nu=2.5) + WhiteKernel(noise_level=0.0204)\n",
      "  best_LML: -15.438\n",
      "  mu(x*): 3115.782549 | sigma(x*): 159.415361\n",
      "  exploration_ratio (proxy): 0.049\n",
      "  LML candidates:\n",
      "    - -16.066 :: 1.41**2 * RBF(length_scale=[0.452, 50, 0.542, 0.358]) + WhiteKernel(noise_level=1.71e-10)\n",
      "    - -16.312 :: 3.69**2 * Matern(length_scale=[50, 5.06, 0.673, 14.2], nu=1.5) + WhiteKernel(noise_level=0.0181)\n",
      "    - -15.438 :: 4.07**2 * Matern(length_scale=[50, 3.96, 0.505, 12.4], nu=2.5) + WhiteKernel(noise_level=0.0204)\n",
      "\n",
      "Function 6 (f6_5d): EXPLOIT | acquisition=EI | xi=0.001000 | beta=3.000\n",
      "  chosen_kernel: 1.27**2 * RBF(length_scale=[0.457, 0.636, 1.15, 0.916, 0.405]) + WhiteKernel(noise_level=4.24e-10)\n",
      "  best_LML: -20.400\n",
      "  mu(x*): -0.447935 | sigma(x*): 0.130685\n",
      "  exploration_ratio (proxy): 0.225\n",
      "  LML candidates:\n",
      "    - -20.400 :: 1.27**2 * RBF(length_scale=[0.457, 0.636, 1.15, 0.916, 0.405]) + WhiteKernel(noise_level=4.24e-10)\n",
      "    - -20.956 :: 2.12**2 * Matern(length_scale=[1.09, 1.66, 3.03, 2.72, 1.35], nu=1.5) + WhiteKernel(noise_level=9.99e-06)\n",
      "    - -20.692 :: 1.61**2 * Matern(length_scale=[0.677, 1.06, 1.88, 1.62, 0.731], nu=2.5) + WhiteKernel(noise_level=6.55e-10)\n",
      "\n",
      "Function 7 (f7_6d): EXPLORE | acquisition=EI | xi=0.050000 | beta=3.000\n",
      "  chosen_kernel: 0.97**2 * Matern(length_scale=[50, 0.288, 0.0662, 0.192, 50, 0.09], nu=2.5) + WhiteKernel(noise_level=1.1e-05)\n",
      "  best_LML: -17.709\n",
      "  mu(x*): 1.233955 | sigma(x*): 0.177786\n",
      "  exploration_ratio (proxy): 0.122\n",
      "  LML candidates:\n",
      "    - -17.839 :: 1.01**2 * RBF(length_scale=[0.512, 50, 0.294, 0.186, 0.161, 0.264]) + WhiteKernel(noise_level=1e-05)\n",
      "    - -17.777 :: 0.97**2 * Matern(length_scale=[50, 0.338, 0.061, 0.188, 50, 0.0837], nu=1.5) + WhiteKernel(noise_level=9.83e-06)\n",
      "    - -17.709 :: 0.97**2 * Matern(length_scale=[50, 0.288, 0.0662, 0.192, 50, 0.09], nu=2.5) + WhiteKernel(noise_level=1.1e-05)\n",
      "\n",
      "Function 8 (f8_8d): EXPLOIT | acquisition=EI | xi=0.001000 | beta=3.000\n",
      "  chosen_kernel: 6.14**2 * Matern(length_scale=[4.19, 6.52, 3.48, 6.39, 22, 6.86, 4.3, 50], nu=2.5) + WhiteKernel(noise_level=5.32e-12)\n",
      "  best_LML: 5.211\n",
      "  mu(x*): 9.959360 | sigma(x*): 0.044983\n",
      "  exploration_ratio (proxy): 0.004\n",
      "  LML candidates:\n",
      "    - -3.196 :: 1.93**2 * RBF(length_scale=[1.05, 1.54, 0.773, 4.01, 6.02, 8.79, 0.782, 50]) + WhiteKernel(noise_level=5.06e-12)\n",
      "    - 0.073 :: 4.4**2 * Matern(length_scale=[5.11, 7.9, 3.95, 8.84, 22.6, 50, 5.71, 50], nu=1.5) + WhiteKernel(noise_level=1.82e-12)\n",
      "    - 5.211 :: 6.14**2 * Matern(length_scale=[4.19, 6.52, 3.48, 6.39, 22, 6.86, 4.3, 50], nu=2.5) + WhiteKernel(noise_level=5.32e-12)\n",
      "\n",
      "\n",
      "Saved plots under: E:\\eMeritus\\Repository\\BBOCapstoneProject\\ml-ai-capstone-project\\plots\n",
      "Saved history snapshot: E:\\eMeritus\\Repository\\BBOCapstoneProject\\ml-ai-capstone-project\\history\\week_04_to_week_05.json\n"
     ]
    }
   ],
   "source": [
    "#! install python3\n",
    "\"\"\"\n",
    "BBOCapstoneWeeklyInputGeneratorAndAnalysis.ipynb\n",
    "\n",
    "End-to-end weekly workflow for the BBO capstone challenge, with Gaussian Process surrogate modelling and acquisition-based query generation.\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------\n",
    "What it does:\n",
    "1) Loads the provided historical seed datasets (points_*/values_*).\n",
    "2) Appends all weekly observations you have so far (Week 1 .. Week K).\n",
    "3) Fits one Gaussian Process (GP) surrogate per function.\n",
    "4) Automatically selects the best kernel by maximising log-marginal likelihood (LML)\n",
    "   across a small kernel pool: Constant*(RBF | Matern 1.5 | Matern 2.5) + WhiteKernel.\n",
    "5) Chooses the next query point using an acquisition function (EI / PI / UCB).\n",
    "6) Tunes exploration vs exploitation per-function:\n",
    "   - EI/PI uses ξ (xi): smaller = more exploit, larger = more explore\n",
    "   - UCB uses β (beta): smaller = more exploit, larger = more explore\n",
    "7) Saves:\n",
    "   - Portal-formatted next-week queries\n",
    "   - Diagnostics (chosen kernel, LML, ξ/β, μ/σ at x*, exploration proxy)\n",
    "   - Plots to ./plots/funcXX/\n",
    "   - A history snapshot to ./history/week_XX.json (inputs + outputs so far + generated next)\n",
    "\n",
    "Optional (Module 16 alignment):\n",
    "- Fits a small Neural Network surrogate (sklearn MLPRegressor) per function and logs:\n",
    "  - Validation score (quick sanity check)\n",
    "  - Finite-difference \"gradient\" around the best predicted region (directional signal)\n",
    "  This mirrors deep-learning concepts (feature learning / gradients) without replacing the GP,\n",
    "  because GP uncertainty is still the most useful signal for exploration.\n",
    "\n",
    "How to use (step-by-step):\n",
    "1) Put this file in your repo root (same folder as README.md).\n",
    "2) Ensure numpy, scipy, scikit-learn, matplotlib are installed.\n",
    "3) Update the WEEKLY_INPUTS_ALL / WEEKLY_OUTPUTS_ALL lists with your latest week.\n",
    "4) Run:  python bbo_gp_weekly_generator_updated.py\n",
    "5) Copy the printed portal lines (Week K+1 queries) into the submission portal.\n",
    "6) After results return, paste Week K+1 outputs into WEEKLY_OUTPUTS_ALL and rerun.\n",
    "\n",
    "Domain:\n",
    "- Assumes each dimension is in [0, 1] and the portal requires values that begin with \"0\".\n",
    "- This script clips to [0.0, 0.999999] before formatting.\n",
    "\n",
    "Objective:\n",
    "- Maximisation for all 8 functions.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern, RBF, WhiteKernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Silence noisy GP optimisation warnings (length_scales hitting bounds, etc.).\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "\n",
    "ACQUISITION = \"ei\"  # \"ei\", \"pi\", \"ucb\"\n",
    "N_CANDIDATES = 70000\n",
    "RNG_SEED = 123\n",
    "DECIMALS = 6\n",
    "\n",
    "# GP settings\n",
    "NOISE_ALPHA = 1e-10\n",
    "RESTARTS_LOW_D = 10   # 2D–3D\n",
    "RESTARTS_MID_D = 6    # 4D–5D\n",
    "RESTARTS_HIGH_D = 2   # 6D–8D\n",
    "\n",
    "# Kernel bounds (increase if you keep hitting upper bounds)\n",
    "LENGTH_SCALE_BOUNDS = (1e-3, 50.0)\n",
    "WHITE_NOISE_BOUNDS = (1e-12, 1e-1)\n",
    "\n",
    "# Explore vs exploit decision rule:\n",
    "# If last week's y is within tol_frac of best-so-far (relative to range), exploit; else explore.\n",
    "EXPLOIT_TOL_FRAC_OF_RANGE = 0.10\n",
    "\n",
    "# EI/PI exploration parameter\n",
    "XI_EXPLOIT = 0.001\n",
    "XI_EXPLORE = 0.05\n",
    "\n",
    "# UCB exploration parameter\n",
    "BETA_EXPLOIT = 1.0\n",
    "BETA_EXPLORE = 3.0\n",
    "\n",
    "# Output folders\n",
    "PLOTS_DIR = Path(\"plots\")\n",
    "HISTORY_DIR = Path(\"history\")\n",
    "\n",
    "# Plot params\n",
    "GRID_RES_2D = 120\n",
    "MAX_POINTS_FOR_PCA_SCATTER = 5000\n",
    "\n",
    "# Optional: Neural Network surrogate diagnostics (Module 16 alignment)\n",
    "USE_NN_SURROGATE_DIAGNOSTICS = True\n",
    "NN_HIDDEN_LAYER_SIZES = (64, 64)\n",
    "NN_MAX_ITER = 2000\n",
    "NN_RANDOM_STATE = 7\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PORTAL FORMATTER\n",
    "# =========================\n",
    "def fmt_query(x: np.ndarray, decimals: int = DECIMALS) -> str:\n",
    "    \"\"\"\n",
    "    Format x as '0.xxxxxx-0.yyyyyy-...' with six decimals.\n",
    "    The portal requires each component to begin with 0, so we clip to [0.0, 0.999999].\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float).reshape(-1)\n",
    "    x = np.clip(x, 0.0, 0.999999)\n",
    "    return \"-\".join([f\"{v:.{decimals}f}\" for v in x])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ACQUISITION FUNCTIONS\n",
    "# =========================\n",
    "def acq_ucb(mu: np.ndarray, sigma: np.ndarray, beta: float) -> np.ndarray:\n",
    "    return mu + beta * sigma\n",
    "\n",
    "\n",
    "def acq_pi(mu: np.ndarray, sigma: np.ndarray, y_best: float, xi: float) -> np.ndarray:\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    z = (mu - y_best - xi) / sigma\n",
    "    return norm.cdf(z)\n",
    "\n",
    "\n",
    "def acq_ei(mu: np.ndarray, sigma: np.ndarray, y_best: float, xi: float) -> np.ndarray:\n",
    "    sigma = np.maximum(sigma, 1e-12)\n",
    "    imp = mu - y_best - xi\n",
    "    z = imp / sigma\n",
    "    return imp * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EXPLORE / EXPLOIT TUNING\n",
    "# =========================\n",
    "def decide_mode_maximise(y_last: float, y_hist: np.ndarray, tol_frac: float) -> str:\n",
    "    \"\"\"\n",
    "    Decide 'exploit' vs 'explore' using last week's output vs best-so-far (relative to range).\n",
    "    \"\"\"\n",
    "    y_hist = np.asarray(y_hist, float).reshape(-1)\n",
    "    best = float(np.max(y_hist))\n",
    "    worst = float(np.min(y_hist))\n",
    "    span = max(best - worst, 1e-12)\n",
    "    dist_frac = (best - float(y_last)) / span\n",
    "    return \"exploit\" if dist_frac <= tol_frac else \"explore\"\n",
    "\n",
    "\n",
    "def tune_params(mode: str, acquisition: str) -> Dict[str, float]:\n",
    "    acquisition = acquisition.lower().strip()\n",
    "    if acquisition in (\"ei\", \"pi\"):\n",
    "        return {\"xi\": XI_EXPLOIT if mode == \"exploit\" else XI_EXPLORE}\n",
    "    if acquisition == \"ucb\":\n",
    "        return {\"beta\": BETA_EXPLOIT if mode == \"exploit\" else BETA_EXPLORE}\n",
    "    raise ValueError(\"ACQUISITION must be one of: ei, pi, ucb\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# KERNEL SELECTION BY LML\n",
    "# =========================\n",
    "def restarts_for_dim(dim: int) -> int:\n",
    "    if dim <= 3:\n",
    "        return RESTARTS_LOW_D\n",
    "    if dim <= 5:\n",
    "        return RESTARTS_MID_D\n",
    "    return RESTARTS_HIGH_D\n",
    "\n",
    "\n",
    "def make_kernel_pool(dim: int) -> List[Any]:\n",
    "    ls0 = 0.30 if dim <= 3 else (0.40 if dim <= 5 else 0.60)\n",
    "    base = [\n",
    "        RBF(length_scale=np.ones(dim) * ls0, length_scale_bounds=LENGTH_SCALE_BOUNDS),\n",
    "        Matern(length_scale=np.ones(dim) * ls0, length_scale_bounds=LENGTH_SCALE_BOUNDS, nu=1.5),\n",
    "        Matern(length_scale=np.ones(dim) * ls0, length_scale_bounds=LENGTH_SCALE_BOUNDS, nu=2.5),\n",
    "    ]\n",
    "    pool: List[Any] = []\n",
    "    for bk in base:\n",
    "        pool.append(\n",
    "            ConstantKernel(1.0, (1e-3, 1e3)) * bk\n",
    "            + WhiteKernel(noise_level=1e-5, noise_level_bounds=WHITE_NOISE_BOUNDS)\n",
    "        )\n",
    "    return pool\n",
    "\n",
    "\n",
    "def fit_gp_and_lml(X: np.ndarray, y: np.ndarray, kernel: Any, seed: int, n_restarts: int):\n",
    "    gp = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        alpha=NOISE_ALPHA,\n",
    "        normalize_y=True,\n",
    "        n_restarts_optimizer=n_restarts,\n",
    "        random_state=seed,\n",
    "    )\n",
    "    gp.fit(X, y)\n",
    "    lml = float(gp.log_marginal_likelihood(gp.kernel_.theta))\n",
    "    return gp, lml\n",
    "\n",
    "\n",
    "def fit_best_gp_by_lml(X: np.ndarray, y: np.ndarray, dim: int, seed: int):\n",
    "    pool = make_kernel_pool(dim)\n",
    "    n_restarts = restarts_for_dim(dim)\n",
    "\n",
    "    best_gp: Optional[GaussianProcessRegressor] = None\n",
    "    best_lml = -np.inf\n",
    "    details: List[Tuple[str, float]] = []\n",
    "\n",
    "    for j, kernel in enumerate(pool):\n",
    "        gp, lml = fit_gp_and_lml(X, y, kernel, seed=seed + 17 * j, n_restarts=n_restarts)\n",
    "        kstr = str(gp.kernel_)\n",
    "        details.append((kstr, float(lml)))\n",
    "        if lml > best_lml:\n",
    "            best_lml = float(lml)\n",
    "            best_gp = gp\n",
    "\n",
    "    assert best_gp is not None\n",
    "    return best_gp, str(best_gp.kernel_), float(best_lml), details\n",
    "\n",
    "\n",
    "# =========================\n",
    "# NN SURROGATE DIAGNOSTICS (optional)\n",
    "# =========================\n",
    "def nn_surrogate_diagnostics(X: np.ndarray, y: np.ndarray, *, seed: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train a small MLP surrogate (tabular NN) and report:\n",
    "    - holdout R^2 (if enough data)\n",
    "    - finite-difference gradient around the best predicted point\n",
    "    This is intentionally lightweight and used for diagnostics, not for uncertainty.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, float)\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "\n",
    "    report: Dict[str, Any] = {\"enabled\": True}\n",
    "\n",
    "    if X.shape[0] < 6:\n",
    "        report[\"note\"] = \"Too few points for reliable NN diagnostics.\"\n",
    "        return report\n",
    "\n",
    "    # Holdout split (tiny datasets => keep it simple)\n",
    "    test_size = 0.25 if X.shape[0] >= 12 else 0.33\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    model = Pipeline(\n",
    "        steps=[\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"mlp\", MLPRegressor(\n",
    "                hidden_layer_sizes=NN_HIDDEN_LAYER_SIZES,\n",
    "                activation=\"relu\",\n",
    "                solver=\"adam\",\n",
    "                alpha=1e-4,\n",
    "                learning_rate_init=1e-3,\n",
    "                max_iter=NN_MAX_ITER,\n",
    "                random_state=seed,\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "    model.fit(Xtr, ytr)\n",
    "    r2 = float(model.score(Xte, yte))\n",
    "    report[\"holdout_r2\"] = r2\n",
    "\n",
    "    # Find a local \"best\" input according to the NN and approximate gradient there\n",
    "    rng = np.random.default_rng(seed + 999)\n",
    "    Xcand = rng.uniform(0.0, 1.0, size=(5000, X.shape[1]))\n",
    "    ypred = model.predict(Xcand)\n",
    "    x0 = Xcand[int(np.argmax(ypred))]\n",
    "\n",
    "    eps = 1e-3\n",
    "    grad = np.zeros_like(x0)\n",
    "    base = float(model.predict(x0.reshape(1, -1))[0])\n",
    "    for d in range(x0.size):\n",
    "        x_plus = x0.copy()\n",
    "        x_minus = x0.copy()\n",
    "        x_plus[d] = min(0.999999, x_plus[d] + eps)\n",
    "        x_minus[d] = max(0.0, x_minus[d] - eps)\n",
    "        f_plus = float(model.predict(x_plus.reshape(1, -1))[0])\n",
    "        f_minus = float(model.predict(x_minus.reshape(1, -1))[0])\n",
    "        grad[d] = (f_plus - f_minus) / (2 * eps)\n",
    "\n",
    "    report[\"nn_best_x\"] = x0.tolist()\n",
    "    report[\"nn_best_pred\"] = float(np.max(ypred))\n",
    "    report[\"fd_grad_at_nn_best\"] = grad.tolist()\n",
    "    report[\"fd_grad_l1\"] = float(np.sum(np.abs(grad)))\n",
    "    report[\"fd_grad_top_dims\"] = np.argsort(-np.abs(grad))[: min(5, x0.size)].tolist()\n",
    "    return report\n",
    "\n",
    "\n",
    "# =========================\n",
    "# EXPLORATION PROXY\n",
    "# =========================\n",
    "def exploration_ratio(mu: float, sigma: float, acquisition: str, xi: float, beta: float) -> float:\n",
    "    \"\"\"\n",
    "    A simple proxy: how much uncertainty contributes relative to mean at the chosen point.\n",
    "    \"\"\"\n",
    "    acquisition = acquisition.lower().strip()\n",
    "    if acquisition == \"ucb\":\n",
    "        return float((beta * sigma) / (abs(mu) + beta * sigma + 1e-12))\n",
    "    return float(sigma / (abs(mu) + sigma + xi + 1e-12))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PROPOSE NEXT POINT\n",
    "# =========================\n",
    "def propose_next_point(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    dim: int,\n",
    "    *,\n",
    "    acquisition: str,\n",
    "    xi: float,\n",
    "    beta: float,\n",
    "    seed: int,\n",
    "    n_candidates: int,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    gp, kernel_str, best_lml, lml_details = fit_best_gp_by_lml(X, y, dim=dim, seed=seed)\n",
    "\n",
    "    # Candidate set: uniform in [0,1]^d\n",
    "    Xcand = rng.uniform(0.0, 1.0, size=(n_candidates, dim))\n",
    "    mu, sigma = gp.predict(Xcand, return_std=True)\n",
    "    mu = mu.reshape(-1)\n",
    "    sigma = sigma.reshape(-1)\n",
    "\n",
    "    y_best = float(np.max(y))\n",
    "    a = acquisition.lower().strip()\n",
    "\n",
    "    if a == \"ei\":\n",
    "        score = acq_ei(mu, sigma, y_best=y_best, xi=xi)\n",
    "    elif a == \"pi\":\n",
    "        score = acq_pi(mu, sigma, y_best=y_best, xi=xi)\n",
    "    elif a == \"ucb\":\n",
    "        score = acq_ucb(mu, sigma, beta=beta)\n",
    "    else:\n",
    "        raise ValueError(\"ACQUISITION must be one of: ei, pi, ucb\")\n",
    "\n",
    "    best_idx = int(np.argmax(score))\n",
    "    x_next = Xcand[best_idx]\n",
    "    mu_best = float(mu[best_idx])\n",
    "    sigma_best = float(sigma[best_idx])\n",
    "    ratio = exploration_ratio(mu_best, sigma_best, acquisition, xi, beta)\n",
    "\n",
    "    report = {\n",
    "        \"kernel\": kernel_str,\n",
    "        \"best_lml\": float(best_lml),\n",
    "        \"lml_candidates\": [(k, float(l)) for k, l in lml_details],\n",
    "        \"mu_at_choice\": mu_best,\n",
    "        \"sigma_at_choice\": sigma_best,\n",
    "        \"exploration_ratio\": ratio,\n",
    "    }\n",
    "    return x_next, fmt_query(x_next), report, gp\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PLOTTING\n",
    "# =========================\n",
    "def ensure_func_plot_dir(func_idx: int) -> Path:\n",
    "    d = PLOTS_DIR / f\"func{func_idx:02d}\"\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "\n",
    "def plot_y_over_iterations(func_idx: int, key: str, y: np.ndarray, out_path: Path) -> None:\n",
    "    y = np.asarray(y, float).reshape(-1)\n",
    "    it = np.arange(1, len(y) + 1)\n",
    "    plt.figure()\n",
    "    plt.plot(it, y, marker=\"o\")\n",
    "    plt.axhline(np.max(y), linestyle=\"--\")\n",
    "    plt.title(f\"{key} (Function {func_idx}) - y over iterations\")\n",
    "    plt.xlabel(\"Observation index\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_2d_gp_mean_contour(\n",
    "    func_idx: int,\n",
    "    key: str,\n",
    "    gp: GaussianProcessRegressor,\n",
    "    X_obs: np.ndarray,\n",
    "    y_obs: np.ndarray,\n",
    "    x_next: np.ndarray,\n",
    "    out_path: Path,\n",
    "    grid_res: int = GRID_RES_2D,\n",
    ") -> None:\n",
    "    xs = np.linspace(0.0, 1.0, grid_res)\n",
    "    ys = np.linspace(0.0, 1.0, grid_res)\n",
    "    X1, X2 = np.meshgrid(xs, ys)\n",
    "    grid = np.column_stack([X1.ravel(), X2.ravel()])\n",
    "    mu = gp.predict(grid).reshape(grid_res, grid_res)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.contourf(X1, X2, mu, levels=20)\n",
    "    plt.scatter(X_obs[:, 0], X_obs[:, 1], c=y_obs, marker=\"o\")\n",
    "    plt.scatter([x_next[0]], [x_next[1]], marker=\"X\", s=120)\n",
    "    plt.title(f\"{key} (Function {func_idx}) - GP mean (2D)\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_pca_scatter(\n",
    "    func_idx: int,\n",
    "    key: str,\n",
    "    X_obs: np.ndarray,\n",
    "    y_obs: np.ndarray,\n",
    "    x_next: np.ndarray,\n",
    "    out_path: Path,\n",
    ") -> None:\n",
    "    X_obs = np.asarray(X_obs, float)\n",
    "    y_obs = np.asarray(y_obs, float).reshape(-1)\n",
    "\n",
    "    if X_obs.shape[0] > MAX_POINTS_FOR_PCA_SCATTER:\n",
    "        idx = np.random.default_rng(RNG_SEED + func_idx).choice(\n",
    "            X_obs.shape[0], size=MAX_POINTS_FOR_PCA_SCATTER, replace=False\n",
    "        )\n",
    "        X_plot = X_obs[idx]\n",
    "        y_plot = y_obs[idx]\n",
    "    else:\n",
    "        X_plot, y_plot = X_obs, y_obs\n",
    "\n",
    "    X_stack = np.vstack([X_plot, x_next.reshape(1, -1)])\n",
    "    pca = PCA(n_components=2, random_state=RNG_SEED + func_idx)\n",
    "    Z = pca.fit_transform(X_stack)\n",
    "    Z_obs = Z[:-1]\n",
    "    Z_next = Z[-1]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(Z_obs[:, 0], Z_obs[:, 1], c=y_plot, marker=\"o\")\n",
    "    plt.scatter([Z_next[0]], [Z_next[1]], marker=\"X\", s=120)\n",
    "    plt.title(f\"{key} (Function {func_idx}) - PCA projection\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATA WRAPPER\n",
    "# =========================\n",
    "@dataclass\n",
    "class FunctionDataset:\n",
    "    key: str\n",
    "    dim: int\n",
    "    X: np.ndarray\n",
    "    y: np.ndarray\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.X = np.asarray(self.X, float).reshape(-1, self.dim)\n",
    "        self.y = np.asarray(self.y, float).reshape(-1)\n",
    "        if self.X.shape[0] != self.y.shape[0]:\n",
    "            raise ValueError(f\"{self.key}: X rows != y rows\")\n",
    "\n",
    "    def append(self, x_new: np.ndarray, y_new: float) -> None:\n",
    "        x_new = np.asarray(x_new, float).reshape(1, self.dim)\n",
    "        self.X = np.vstack([self.X, x_new])\n",
    "        self.y = np.concatenate([self.y, [float(y_new)]])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HISTORICAL SEED DATA\n",
    "# =========================\n",
    "# NOTE: These are your provided seed datasets (unchanged).\n",
    "\n",
    "# 2D DATASET A (tiny values)\n",
    "points_2d_a = np.array([\n",
    "    [0.31940389, 0.76295937],\n",
    "    [0.57432921, 0.87989810],\n",
    "    [0.73102363, 0.73299988],\n",
    "    [0.84035342, 0.26473161],\n",
    "    [0.65011406, 0.68152635],\n",
    "    [0.41043714, 0.14755430],\n",
    "    [0.31269116, 0.07872278],\n",
    "    [0.68341817, 0.86105746],\n",
    "    [0.08250725, 0.40348751],\n",
    "])\n",
    "values_2d_a = np.array([\n",
    "    1.3226770395454077e-79,\n",
    "    1.0330782375230975e-46,\n",
    "    7.710875114502849e-16,\n",
    "    3.341771007676023e-124,\n",
    "    -0.0036060626443634764,\n",
    "    -2.1592490357331095e-54,\n",
    "    -2.0890932702320842e-91,\n",
    "    2.5350011535584046e-40,\n",
    "    3.6067711901420254e-81,\n",
    "])\n",
    "\n",
    "# 2D DATASET B\n",
    "points_2d_b = np.array([\n",
    "    [0.66579958, 0.12396913],\n",
    "    [0.87779099, 0.77862750],\n",
    "    [0.14269907, 0.34900513],\n",
    "    [0.84527543, 0.71112027],\n",
    "    [0.45464714, 0.29045518],\n",
    "    [0.57771284, 0.77197318],\n",
    "    [0.43816606, 0.68501826],\n",
    "    [0.34174959, 0.02869772],\n",
    "    [0.33864816, 0.21386725],\n",
    "])\n",
    "values_2d_b = np.array([\n",
    "    0.5389961189269181,\n",
    "    0.42058623962798264,\n",
    "    -0.06562362443733738,\n",
    "    0.293992912410866,\n",
    "    0.2149645101004509,\n",
    "    0.023105549798190586,\n",
    "    0.24461934400448035,\n",
    "    0.0387490151561584,\n",
    "    -0.013857618149729824,\n",
    "])\n",
    "\n",
    "# 3D DATASET\n",
    "points_3d = np.array([\n",
    "    [0.17152521, 0.34391687, 0.24873720],\n",
    "    [0.24211446, 0.64407427, 0.27243281],\n",
    "    [0.53490572, 0.39850092, 0.17338873],\n",
    "    [0.49258141, 0.61159319, 0.34017639],\n",
    "    [0.13462167, 0.21991724, 0.45820622],\n",
    "    [0.34552327, 0.94135983, 0.26936348],\n",
    "    [0.15183663, 0.43999062, 0.99088187],\n",
    "    [0.64550284, 0.39714294, 0.91977134],\n",
    "    [0.74691195, 0.28419631, 0.22629985],\n",
    "    [0.17047699, 0.69703240, 0.14916943],\n",
    "    [0.22054934, 0.29782524, 0.34355534],\n",
    "    [0.66601366, 0.67198515, 0.24629530],\n",
    "    [0.04680895, 0.23136024, 0.77061759],\n",
    "    [0.60009728, 0.72513573, 0.06608864],\n",
    "])\n",
    "values_3d = np.array([\n",
    "    -0.11212220046256897,\n",
    "    -0.08796286022736445,\n",
    "    -0.11141465429532400,\n",
    "    -0.034835313350078584,\n",
    "    -0.04800758439218157,\n",
    "    -0.11062091307282658,\n",
    "    -0.39892551314630110,\n",
    "    -0.11386851478863991,\n",
    "    -0.13146060864136055,\n",
    "    -0.09418956091057398,\n",
    "    -0.04694740582651916,\n",
    "    -0.10596503573558178,\n",
    "    -0.11804825644688696,\n",
    "    -0.036377828071632486,\n",
    "])\n",
    "\n",
    "# 4D DATASET A (negative)\n",
    "points_4d_a = np.array([\n",
    "    [0.89698105, 0.72562797, 0.17540431, 0.70169437],\n",
    "    [0.88935640, 0.49958786, 0.53926886, 0.50878344],\n",
    "    [0.25094624, 0.03369313, 0.14538002, 0.49493242],\n",
    "    [0.34696206, 0.00625040, 0.76056361, 0.61302356],\n",
    "    [0.12487118, 0.12977019, 0.38440048, 0.28707610],\n",
    "    [0.80130271, 0.50023109, 0.70664456, 0.19510284],\n",
    "    [0.24770826, 0.06044543, 0.04218635, 0.44132425],\n",
    "    [0.74670224, 0.75709150, 0.36935306, 0.20656628],\n",
    "    [0.40066503, 0.07257425, 0.88676825, 0.24384229],\n",
    "    [0.62607060, 0.58675126, 0.43880578, 0.77885769],\n",
    "    [0.95713529, 0.59764438, 0.76611385, 0.77620991],\n",
    "    [0.73281243, 0.14524998, 0.47681272, 0.13336573],\n",
    "    [0.65511548, 0.07239183, 0.68715175, 0.08151656],\n",
    "    [0.21973443, 0.83203134, 0.48286416, 0.08256923],\n",
    "    [0.48859419, 0.21196510, 0.93917791, 0.37619173],\n",
    "    [0.16713049, 0.87655456, 0.21723954, 0.95980098],\n",
    "    [0.21691119, 0.16608583, 0.24137226, 0.77006248],\n",
    "    [0.38748784, 0.80453226, 0.75179548, 0.72382744],\n",
    "    [0.98562189, 0.66693268, 0.15678328, 0.85653480],\n",
    "    [0.03782483, 0.66485335, 0.16198218, 0.25392378],\n",
    "    [0.68348638, 0.90277010, 0.33541983, 0.99948256],\n",
    "    [0.17034731, 0.75695908, 0.27652049, 0.53123150],\n",
    "    [0.85965692, 0.91959232, 0.20613873, 0.09779683],\n",
    "    [0.28213837, 0.50598691, 0.53053084, 0.09630162],\n",
    "    [0.32607578, 0.47236690, 0.45319200, 0.10588734],\n",
    "    [0.94838936, 0.89451301, 0.85163782, 0.55219629],\n",
    "    [0.66495539, 0.04656628, 0.11677747, 0.79371778],\n",
    "    [0.57776561, 0.42877174, 0.42582587, 0.24900741],\n",
    "    [0.73861301, 0.48210263, 0.70936644, 0.50397001],\n",
    "])\n",
    "values_4d_a = np.array([\n",
    "    -22.108287785435817,\n",
    "    -14.601396631953161,\n",
    "    -11.699932463834426,\n",
    "    -16.053765110568296,\n",
    "    -10.069633426012889,\n",
    "    -15.487082537755288,\n",
    "    -12.681684976815650,\n",
    "    -16.026399768983520,\n",
    "    -17.049234647535723,\n",
    "    -12.741765988316185,\n",
    "    -27.316396356142608,\n",
    "    -13.527648872277506,\n",
    "    -16.679115197479913,\n",
    "    -16.507158564282340,\n",
    "    -17.817999338829490,\n",
    "    -26.561820829779602,\n",
    "    -12.758324216781741,\n",
    "    -19.441557624451722,\n",
    "    -28.903273673833770,\n",
    "    -13.702746938161251,\n",
    "    -29.427091401989347,\n",
    "    -11.565741989583191,\n",
    "    -26.857786437773637,\n",
    "    -7.9667753510303925,\n",
    "    -6.702089254839066,\n",
    "    -32.625660215962455,\n",
    "    -19.989497926795560,\n",
    "    -4.025542281908162,\n",
    "    -13.122782331852594,\n",
    "])\n",
    "\n",
    "# 4D DATASET B (positive)\n",
    "points_4d_b = np.array([\n",
    "    [0.19144708, 0.03819337, 0.60741781, 0.41458414],\n",
    "    [0.75865295, 0.53651774, 0.65600038, 0.36034155],\n",
    "    [0.43834987, 0.80433970, 0.21024527, 0.15129482],\n",
    "    [0.70605083, 0.53419196, 0.26424335, 0.48208755],\n",
    "    [0.83647799, 0.19360965, 0.66389270, 0.78564888],\n",
    "    [0.68343225, 0.11866264, 0.82904591, 0.56757661],\n",
    "    [0.55362148, 0.66734998, 0.32380582, 0.81486975],\n",
    "    [0.35235627, 0.32224153, 0.11697937, 0.47311252],\n",
    "    [0.15378571, 0.72938169, 0.42259844, 0.44307417],\n",
    "    [0.46344227, 0.63002451, 0.10790646, 0.95764390],\n",
    "    [0.67749115, 0.35850951, 0.47959222, 0.07288048],\n",
    "    [0.58397341, 0.14724265, 0.34809746, 0.42861465],\n",
    "    [0.30688872, 0.31687813, 0.62263448, 0.09539906],\n",
    "    [0.51114177, 0.81795700, 0.72871042, 0.11235362],\n",
    "    [0.43893338, 0.77409176, 0.37816709, 0.93369621],\n",
    "    [0.22418902, 0.84648049, 0.87948418, 0.87851568],\n",
    "    [0.72526172, 0.47987049, 0.08894684, 0.75976022],\n",
    "    [0.35548161, 0.63961937, 0.41761768, 0.12260384],\n",
    "    [0.11987923, 0.86254031, 0.64333133, 0.84980383],\n",
    "])\n",
    "values_4d_b = np.array([\n",
    "    64.443439863301,\n",
    "    18.30137959857266,\n",
    "    0.1129397953712203,\n",
    "    4.210898128938665,\n",
    "    258.3705254462536,\n",
    "    78.43438888779464,\n",
    "    57.57153693261287,\n",
    "    109.5718755614928,\n",
    "    8.847991759070865,\n",
    "    233.22361017104996,\n",
    "    24.423088313942344,\n",
    "    64.42014681963983,\n",
    "    63.47671578508436,\n",
    "    79.72912992694343,\n",
    "    355.8068177560159,\n",
    "    1088.8596181962705,\n",
    "    28.866751637393822,\n",
    "    45.181570346703786,\n",
    "    431.6127567592104,\n",
    "])\n",
    "\n",
    "# 5D DATASET (used for Function 6 in your mapping)\n",
    "points_5d = np.array([\n",
    "    [0.72818610, 0.15469257, 0.73255167, 0.69399651, 0.05640131],\n",
    "    [0.24238435, 0.84409997, 0.57780910, 0.67902128, 0.50195289],\n",
    "    [0.72952261, 0.74810620, 0.67977464, 0.35655228, 0.67105368],\n",
    "    [0.77062024, 0.11440374, 0.04677993, 0.64832428, 0.27354905],\n",
    "    [0.61881230, 0.33180214, 0.18728787, 0.75623847, 0.32883480],\n",
    "    [0.78495809, 0.91068235, 0.70812010, 0.95922543, 0.00491150],\n",
    "    [0.14511079, 0.89668460, 0.89632223, 0.72627154, 0.23627199],\n",
    "    [0.94506907, 0.28845905, 0.97880576, 0.96165559, 0.59801594],\n",
    "    [0.12572016, 0.86272469, 0.02854433, 0.24660527, 0.75120624],\n",
    "    [0.75759436, 0.35583141, 0.01652290, 0.43420720, 0.11243304],\n",
    "    [0.53679690, 0.30878091, 0.41187929, 0.38822518, 0.52252830],\n",
    "    [0.95773967, 0.23566857, 0.09914585, 0.15680593, 0.07131737],\n",
    "    [0.62930790, 0.80348368, 0.81140844, 0.04561319, 0.11062446],\n",
    "    [0.02173531, 0.42808424, 0.83593944, 0.48948866, 0.51108173],\n",
    "    [0.43934426, 0.69892383, 0.42682022, 0.10947609, 0.87788847],\n",
    "    [0.25890557, 0.79367771, 0.64211390, 0.19667346, 0.59310318],\n",
    "    [0.43216593, 0.71561781, 0.34181910, 0.70499988, 0.61496184],\n",
    "    [0.78287982, 0.53633586, 0.44328356, 0.85969983, 0.01032599],\n",
    "    [0.92177620, 0.93187122, 0.41487637, 0.59505727, 0.73562569],\n",
    "])\n",
    "values_5d = np.array([\n",
    "    -0.7142649478202404,\n",
    "    -1.2099552446764819,\n",
    "    -1.6721999396105658,\n",
    "    -1.5360577085694833,\n",
    "    -0.8292365522578722,\n",
    "    -1.2470489267904978,\n",
    "    -1.2337863805718483,\n",
    "    -1.6943434420704928,\n",
    "    -2.5711696316081234,\n",
    "    -1.3091163528236960,\n",
    "    -1.1447848512705794,\n",
    "    -1.9126771431925136,\n",
    "    -1.6228389517771730,\n",
    "    -1.3566821093823407,\n",
    "    -2.0184253993747820,\n",
    "    -1.7025578405650035,\n",
    "    -1.2942469649550403,\n",
    "    -0.9357565553342914,\n",
    "    -2.1557677641786004,\n",
    "])\n",
    "\n",
    "# 6D DATASET (Function 7)\n",
    "points_6d = np.array([\n",
    "    [0.27262382, 0.32449536, 0.89710881, 0.83295115, 0.15406269, 0.79586362],\n",
    "    [0.54300258, 0.92469390, 0.34156746, 0.64648585, 0.71844033, 0.34313266],\n",
    "    [0.09083225, 0.66152938, 0.06593091, 0.25857701, 0.96345285, 0.64026540],\n",
    "    [0.11886697, 0.61505494, 0.90581639, 0.85530030, 0.41363143, 0.58523563],\n",
    "    [0.63021764, 0.83809690, 0.68001305, 0.73189509, 0.52673671, 0.34842921],\n",
    "    [0.76491917, 0.25588292, 0.60908422, 0.21807904, 0.32294277, 0.09579366],\n",
    "    [0.05789554, 0.49167222, 0.24742222, 0.21811844, 0.42042833, 0.73096984],\n",
    "    [0.19525188, 0.07922665, 0.55458046, 0.17056682, 0.01494418, 0.10703171],\n",
    "    [0.64230298, 0.83687455, 0.02179269, 0.10148801, 0.68307083, 0.69241640],\n",
    "])\n",
    "values_6d = np.array([\n",
    "    0.6044326958745716,\n",
    "    0.5627530668655433,\n",
    "    0.007503236678049401,\n",
    "    0.06142430250355775,\n",
    "    0.27304680126759867,\n",
    "    0.08374657232015563,\n",
    "    1.3649683044991994,\n",
    "    0.09264495494793601,\n",
    "    0.017869598722495817,\n",
    "])\n",
    "\n",
    "# 8D DATASET (Function 8)\n",
    "points_8d = np.array([\n",
    "    [0.60499445,0.29221502,0.90845275,0.35550624,0.20166872,0.57533801,0.31031095,0.73428138],\n",
    "    [0.17800696,0.56622265,0.99486184,0.21032501,0.32015266,0.70790879,0.63538449,0.10713163],\n",
    "    [0.00907698,0.81162615,0.52052036,0.07568668,0.26511183,0.09165169,0.59241515,0.36732026],\n",
    "    [0.50602816,0.65373012,0.36341078,0.17798105,0.09372830,0.19742533,0.75582690,0.29247234],\n",
    "    [0.35990926,0.24907568,0.49599717,0.70921498,0.11498719,0.28920692,0.55729515,0.59388173],\n",
    "    [0.77881834,0.00341950,0.33798313,0.51952778,0.82090699,0.53724669,0.55134710,0.66003209],\n",
    "    [0.90864932,0.06224970,0.23825955,0.76660355,0.13233596,0.99024381,0.68806782,0.74249594],\n",
    "    [0.58637144,0.88073573,0.74502075,0.54603485,0.00964888,0.74899176,0.23090707,0.09791562],\n",
    "    [0.76113733,0.85467239,0.38212433,0.33735198,0.68970832,0.30985305,0.63137968,0.04195607],\n",
    "    [0.98493320,0.69950626,0.99888550,0.18014846,0.58014315,0.23108719,0.49082694,0.31368272],\n",
    "    [0.11207131,0.43773566,0.59659878,0.59277563,0.22698177,0.41010452,0.92123758,0.67475276],\n",
    "    [0.79188751,0.57619134,0.69452836,0.28342378,0.13675546,0.27916186,0.84276726,0.62532792],\n",
    "    [0.14355030,0.93741452,0.23232482,0.00904349,0.41457893,0.40932517,0.55377852,0.20584080],\n",
    "    [0.76991655,0.45875909,0.55900044,0.69460444,0.50319902,0.72834638,0.78425353,0.66313109],\n",
    "    [0.05644741,0.06595555,0.02292868,0.03878647,0.40393544,0.80105533,0.48830701,0.89308498],\n",
    "    [0.86243745,0.48273382,0.28186940,0.54410223,0.88749026,0.38265469,0.60190199,0.47646169],\n",
    "    [0.35151190,0.59006494,0.90943630,0.67840835,0.21282566,0.08846038,0.41015300,0.19572429],\n",
    "    [0.73590364,0.03461189,0.72803027,0.14742652,0.29574314,0.44511731,0.97517969,0.37433978],\n",
    "    [0.68029397,0.25510465,0.86218799,0.13439582,0.32632920,0.28790687,0.43501048,0.36420013],\n",
    "    [0.04432925,0.01358149,0.25819824,0.57764416,0.05127992,0.15856307,0.59103012,0.07795293],\n",
    "    [0.77834548,0.75114565,0.31414221,0.90298577,0.33538166,0.38632267,0.74897249,0.98875510],\n",
    "    [0.89888711,0.52364170,0.87678325,0.21869645,0.90026089,0.28276624,0.91107791,0.47239822],\n",
    "    [0.14512029,0.11932754,0.42088822,0.38760861,0.15542283,0.87517163,0.51055967,0.72861058],\n",
    "    [0.33895442,0.56693202,0.37675110,0.09891573,0.65945169,0.24554809,0.76248278,0.73215347],\n",
    "    [0.17615002,0.29396143,0.97567997,0.79393631,0.92340076,0.03084229,0.80325452,0.59589758],\n",
    "    [0.02894663,0.02827906,0.48137155,0.61317460,0.67266045,0.02211341,0.60148330,0.52488505],\n",
    "    [0.19263987,0.63067728,0.41679584,0.49052929,0.79608602,0.65456706,0.27624119,0.29551759],\n",
    "    [0.94318502,0.21885062,0.72118408,0.42459707,0.98690200,0.53518298,0.71474318,0.96009372],\n",
    "    [0.53272140,0.83369260,0.07139900,0.11681148,0.73069311,0.93737559,0.86650798,0.12790200],\n",
    "    [0.44709584,0.84395253,0.72954612,0.63915138,0.40928714,0.13264569,0.03590888,0.44683847],\n",
    "    [0.38222497,0.55713584,0.85310163,0.33379569,0.26572127,0.48087292,0.23764706,0.76863196],\n",
    "    [0.53281953,0.86230848,0.53826712,0.04944293,0.71970119,0.90670590,0.10823094,0.52534791],\n",
    "    [0.39486519,0.33180167,0.74075430,0.69786172,0.73740444,0.78377681,0.25449546,0.87114551],\n",
    "    [0.98594539,0.87305363,0.07039262,0.05358729,0.73415296,0.52025852,0.81104004,0.10336036],\n",
    "    [0.96457339,0.97397979,0.66375335,0.66221599,0.67312167,0.90523762,0.45887462,0.56091750],\n",
    "    [0.47207071,0.16820264,0.08642757,0.45265551,0.48061922,0.62243949,0.92897446,0.11253627],\n",
    "    [0.85600695,0.63889370,0.32619202,0.66850311,0.24029837,0.21029889,0.16754636,0.96358986],\n",
    "    [0.81003174,0.63504604,0.26954758,0.86960534,0.66192159,0.25225873,0.76567003,0.89054867],\n",
    "    [0.79625252,0.00703653,0.35569738,0.48756605,0.74051962,0.70665010,0.99291449,0.38173437],\n",
    "])\n",
    "values_8d = np.array([\n",
    "    7.398721101163708,\n",
    "    7.005227361900734,\n",
    "    8.45948161622808,\n",
    "    8.284007811285548,\n",
    "    8.606116791392116,\n",
    "    8.541747923679363,\n",
    "    7.327434575740623,\n",
    "    7.299872046566419,\n",
    "    7.957874742347002,\n",
    "    5.5921933895401965,\n",
    "    7.854540990501387,\n",
    "    6.791985783133633,\n",
    "    8.976554022457023,\n",
    "    7.3790829035972365,\n",
    "    9.598482002566342,\n",
    "    8.159983191736115,\n",
    "    7.13162396619294,\n",
    "    6.767962534878629,\n",
    "    7.433744072022712,\n",
    "    9.013075145673822,\n",
    "    7.310893815253165,\n",
    "    5.841067313187262,\n",
    "    9.141639493309754,\n",
    "    8.817558441363609,\n",
    "    6.451943125106222,\n",
    "    8.83074504574746,\n",
    "    9.34427428080805,\n",
    "    6.887846394035938,\n",
    "    8.042212541982503,\n",
    "    7.692368045766445,\n",
    "    7.923758772464366,\n",
    "    8.42175923792568,\n",
    "    8.27806239964175,\n",
    "    7.113457163948368,\n",
    "    6.402588414582601,\n",
    "    8.472936316651243,\n",
    "    7.977684585372973,\n",
    "    7.460872194740431,\n",
    "    7.436593526746213,\n",
    "])\n",
    "\n",
    "\n",
    "# =========================\n",
    "# WEEKLY OBSERVATIONS (Week 1..4) - UPDATE THIS EACH WEEK\n",
    "# =========================\n",
    "# IMPORTANT:\n",
    "# - Each week inputs is a list of 8 np.arrays (one per function)\n",
    "# - Each week outputs is a list/array length 8\n",
    "# - Append new weeks at the end\n",
    "\n",
    "week1_inputs = [\n",
    "    np.array([0.372451, 0.684219]),\n",
    "    np.array([0.815624, 0.243907]),\n",
    "    np.array([0.214578, 0.739215, 0.563482]),\n",
    "    np.array([0.691245, 0.182734, 0.534817, 0.408263]),\n",
    "    np.array([0.456182, 0.827364, 0.319547, 0.672415]),\n",
    "    np.array([0.238415, 0.564738, 0.792164, 0.413826, 0.689541]),\n",
    "    np.array([0.127394, 0.458216, 0.839275, 0.364182, 0.592736, 0.715204]),\n",
    "    np.array([0.091284, 0.376452, 0.648219, 0.823615, 0.214739, 0.587341, 0.732916, 0.459128]),\n",
    "]\n",
    "week1_outputs = [\n",
    "    np.float64(1.5748453958061012e-48),\n",
    "    np.float64(0.18039410845450976),\n",
    "    np.float64(-0.03855585192956583),\n",
    "    np.float64(-8.961029494112594),\n",
    "    np.float64(49.85674062082695),\n",
    "    np.float64(-1.5130754270634885),\n",
    "    np.float64(0.4692517257441858),\n",
    "    np.float64(7.9402805027841),\n",
    "]\n",
    "\n",
    "week2_inputs = [\n",
    "    np.array([0.263232, 0.692120]),\n",
    "    np.array([0.999999, 0.310918]),\n",
    "    np.array([0.171156, 0.820335, 0.517707]),\n",
    "    np.array([0.757035, 0.095945, 0.402324, 0.338791]),\n",
    "    np.array([0.310629, 0.834492, 0.396231, 0.799219]),\n",
    "    np.array([0.203018, 0.547341, 0.773500, 0.466517, 0.605858]),\n",
    "    np.array([0.000000, 0.578647, 0.913483, 0.367752, 0.528534, 0.777934]),\n",
    "    np.array([0.094269, 0.433556, 0.540599, 0.814786, 0.194082, 0.529488, 0.725916, 0.380393]),\n",
    "]\n",
    "week2_outputs = [\n",
    "    np.float64(-8.412448709899239e-70),\n",
    "    np.float64(0.10235357020556336),\n",
    "    np.float64(-0.03061042303613871),\n",
    "    np.float64(-12.209283145814855),\n",
    "    np.float64(151.27449679067803),\n",
    "    np.float64(-1.3242461523900468),\n",
    "    np.float64(0.3975173339469103),\n",
    "    np.float64(8.2293794088801),\n",
    "]\n",
    "\n",
    "week3_inputs = [\n",
    "    np.array([0.704820, 0.153340]),\n",
    "    np.array([0.696501, 0.036321]),\n",
    "    np.array([0.969648, 0.771320, 0.854665]),\n",
    "    np.array([0.416966, 0.404427, 0.356931, 0.406136]),\n",
    "    np.array([0.513167, 0.831782, 0.996220, 0.999037]),\n",
    "    np.array([0.370837, 0.173596, 0.693576, 0.962889, 0.168614]),\n",
    "    np.array([0.225757, 0.439856, 0.295544, 0.723542, 0.196561, 0.797924]),\n",
    "    np.array([0.063471, 0.108669, 0.036989, 0.129464, 0.927252, 0.469168, 0.101991, 0.123106]),\n",
    "]\n",
    "week3_outputs = [\n",
    "    np.float64(-1.594263249992658e-107),\n",
    "    np.float64(0.4377146055554574),\n",
    "    np.float64(-0.036486297266169324),\n",
    "    np.float64(0.6588288043220065),\n",
    "    np.float64(2967.924604693576),\n",
    "    np.float64(-0.6016622426617185),\n",
    "    np.float64(0.25444565237832933),\n",
    "    np.float64(9.9182466822364),\n",
    "]\n",
    "\n",
    "# Week 4 (portal confirmed)\n",
    "week4_inputs = [\n",
    "    np.array([0.763424, 0.919401]),\n",
    "    np.array([0.000020, 0.608134]),\n",
    "    np.array([0.114597, 0.538378, 0.000022]),\n",
    "    np.array([0.425041, 0.428923, 0.330132, 0.432393]),\n",
    "    np.array([0.207234, 0.049908, 0.993246, 0.999556]),\n",
    "    np.array([0.486971, 0.421311, 0.700489, 0.897495, 0.304443]),\n",
    "    np.array([0.109513, 0.742227, 0.296665, 0.334240, 0.160402, 0.722658]),\n",
    "    np.array([0.151714, 0.013381, 0.259014, 0.150928, 0.965973, 0.652543, 0.242138, 0.674780]),\n",
    "]\n",
    "week4_outputs = [\n",
    "    np.float64(2.8055863313478976e-72),\n",
    "    np.float64(-0.09297034681235537),\n",
    "    np.float64(-0.10392147861855096),\n",
    "    np.float64(0.1659692061914524),\n",
    "    np.float64(1562.3727909790937),\n",
    "    np.float64(-0.4440705103815761),\n",
    "    np.float64(0.5817504892733333),\n",
    "    np.float64(9.8848985633335),\n",
    "]\n",
    "\n",
    "WEEKLY_INPUTS_ALL = [week1_inputs, week2_inputs, week3_inputs, week4_inputs]\n",
    "WEEKLY_OUTPUTS_ALL = [week1_outputs, week2_outputs, week3_outputs, week4_outputs]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HISTORY SNAPSHOT\n",
    "# =========================\n",
    "def save_week_snapshot(\n",
    "    *,\n",
    "    week_k: int,\n",
    "    next_week_inputs: List[np.ndarray],\n",
    "    next_week_portal_lines: List[str],\n",
    "    diagnostics: List[Dict[str, Any]],\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Save a JSON snapshot to ./history/week_XX.json containing:\n",
    "    - all observed weeks so far (inputs + outputs)\n",
    "    - next-week generated queries\n",
    "    - diagnostics per function\n",
    "    \"\"\"\n",
    "    HISTORY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    payload: Dict[str, Any] = {\n",
    "        \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"acquisition\": ACQUISITION,\n",
    "        \"week_k_observed\": week_k,\n",
    "        \"weekly_inputs\": [\n",
    "            [np.asarray(x).tolist() for x in week_inputs] for week_inputs in WEEKLY_INPUTS_ALL\n",
    "        ],\n",
    "        \"weekly_outputs\": [\n",
    "            [float(v) for v in week_outputs] for week_outputs in WEEKLY_OUTPUTS_ALL\n",
    "        ],\n",
    "        \"next_week_inputs\": [x.tolist() for x in next_week_inputs],\n",
    "        \"next_week_portal_lines\": next_week_portal_lines,\n",
    "        \"diagnostics\": diagnostics,\n",
    "    }\n",
    "\n",
    "    out_path = HISTORY_DIR / f\"week_{week_k:02d}_to_week_{week_k+1:02d}.json\"\n",
    "    out_path.write_text(json.dumps(payload, indent=2))\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main() -> None:\n",
    "    # Validate weekly inputs/outputs structure\n",
    "    if len(WEEKLY_INPUTS_ALL) != len(WEEKLY_OUTPUTS_ALL):\n",
    "        raise RuntimeError(\"WEEKLY_INPUTS_ALL and WEEKLY_OUTPUTS_ALL must have the same length.\")\n",
    "    for w, (wi, wo) in enumerate(zip(WEEKLY_INPUTS_ALL, WEEKLY_OUTPUTS_ALL), start=1):\n",
    "        if len(wi) != 8:\n",
    "            raise RuntimeError(f\"Week {w} inputs must have 8 entries (one per function).\")\n",
    "        if np.asarray(wo).shape != (8,):\n",
    "            raise RuntimeError(f\"Week {w} outputs must be shape (8,), got {np.asarray(wo).shape}.\")\n",
    "\n",
    "    # Build per-function datasets from historical data\n",
    "    funcs = [\n",
    "        FunctionDataset(\"f1_2d_a\", 2, points_2d_a, values_2d_a),\n",
    "        FunctionDataset(\"f2_2d_b\", 2, points_2d_b, values_2d_b),\n",
    "        FunctionDataset(\"f3_3d\",   3, points_3d,   values_3d),\n",
    "        FunctionDataset(\"f4_4d_a\", 4, points_4d_a, values_4d_a),\n",
    "        FunctionDataset(\"f5_4d_b\", 4, points_4d_b, values_4d_b),\n",
    "        FunctionDataset(\"f6_5d\",   5, points_5d,   values_5d),\n",
    "        FunctionDataset(\"f7_6d\",   6, points_6d,   values_6d),\n",
    "        FunctionDataset(\"f8_8d\",   8, points_8d,   values_8d),\n",
    "    ]\n",
    "\n",
    "    # Append Week 1..K\n",
    "    for w_inputs, w_outputs in zip(WEEKLY_INPUTS_ALL, WEEKLY_OUTPUTS_ALL):\n",
    "        w_outputs = np.asarray(w_outputs, float).reshape(-1)\n",
    "        for i, f in enumerate(funcs):\n",
    "            f.append(w_inputs[i], float(w_outputs[i]))\n",
    "\n",
    "    week_k = len(WEEKLY_OUTPUTS_ALL)\n",
    "    last_week_outputs = np.asarray(WEEKLY_OUTPUTS_ALL[-1], float).reshape(-1)\n",
    "\n",
    "    # Prepare output folders\n",
    "    PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    HISTORY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Generate next-week queries\n",
    "    print(f\"=== Next WEEK {week_k + 1} QUERIES (PORTAL FORMAT) ===\")\n",
    "\n",
    "    next_points: List[np.ndarray] = []\n",
    "    portal_lines: List[str] = []\n",
    "    diagnostics_payload: List[Dict[str, Any]] = []\n",
    "    debug_rows = []  # for printing + plotting\n",
    "\n",
    "    for idx, f in enumerate(funcs, start=1):\n",
    "        mode = decide_mode_maximise(\n",
    "            y_last=float(last_week_outputs[idx - 1]),\n",
    "            y_hist=f.y,\n",
    "            tol_frac=EXPLOIT_TOL_FRAC_OF_RANGE,\n",
    "        )\n",
    "        tuned = tune_params(mode, ACQUISITION)\n",
    "        xi = float(tuned.get(\"xi\", XI_EXPLORE))\n",
    "        beta = float(tuned.get(\"beta\", BETA_EXPLORE))\n",
    "\n",
    "        x_next, portal_line, report, gp = propose_next_point(\n",
    "            f.X,\n",
    "            f.y,\n",
    "            f.dim,\n",
    "            acquisition=ACQUISITION,\n",
    "            xi=xi,\n",
    "            beta=beta,\n",
    "            seed=RNG_SEED + 31 * idx,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "        )\n",
    "\n",
    "        print(portal_line)\n",
    "        next_points.append(np.asarray(x_next, float))\n",
    "        portal_lines.append(portal_line)\n",
    "\n",
    "        # Optional NN diagnostics (Module 16)\n",
    "        nn_report = None\n",
    "        if USE_NN_SURROGATE_DIAGNOSTICS:\n",
    "            nn_report = nn_surrogate_diagnostics(f.X, f.y, seed=NN_RANDOM_STATE + idx)\n",
    "\n",
    "        diag = {\n",
    "            \"function_index\": idx,\n",
    "            \"function_key\": f.key,\n",
    "            \"dim\": f.dim,\n",
    "            \"mode\": mode,\n",
    "            \"acquisition\": ACQUISITION.upper(),\n",
    "            \"xi\": xi,\n",
    "            \"beta\": beta,\n",
    "            \"kernel\": report[\"kernel\"],\n",
    "            \"best_lml\": report[\"best_lml\"],\n",
    "            \"mu_at_choice\": report[\"mu_at_choice\"],\n",
    "            \"sigma_at_choice\": report[\"sigma_at_choice\"],\n",
    "            \"exploration_ratio\": report[\"exploration_ratio\"],\n",
    "            \"lml_candidates\": report[\"lml_candidates\"],\n",
    "            \"nn_diagnostics\": nn_report,\n",
    "        }\n",
    "        diagnostics_payload.append(diag)\n",
    "        debug_rows.append((idx, f, mode, xi, beta, report, gp))\n",
    "\n",
    "    # Save history snapshot (so the repo accumulates week-by-week progress)\n",
    "    snapshot_path = save_week_snapshot(\n",
    "        week_k=week_k,\n",
    "        next_week_inputs=next_points,\n",
    "        next_week_portal_lines=portal_lines,\n",
    "        diagnostics=diagnostics_payload,\n",
    "    )\n",
    "\n",
    "    # Print diagnostics (human readable)\n",
    "    print(\"\\n=== DIAGNOSTICS (kernel / xi-beta / explore-exploit) ===\\n\")\n",
    "    for (idx, f, mode, xi, beta, report, _gp) in debug_rows:\n",
    "        print(\n",
    "            f\"Function {idx} ({f.key}): {mode.upper()} | acquisition={ACQUISITION.upper()} \"\n",
    "            f\"| xi={xi:.6f} | beta={beta:.3f}\"\n",
    "        )\n",
    "        print(f\"  chosen_kernel: {report['kernel']}\")\n",
    "        print(f\"  best_LML: {report['best_lml']:.3f}\")\n",
    "        print(f\"  mu(x*): {report['mu_at_choice']:.6f} | sigma(x*): {report['sigma_at_choice']:.6f}\")\n",
    "        print(f\"  exploration_ratio (proxy): {report['exploration_ratio']:.3f}\")\n",
    "        print(\"  LML candidates:\")\n",
    "        for kstr, lml in report[\"lml_candidates\"]:\n",
    "            print(f\"    - {lml:.3f} :: {kstr}\")\n",
    "        print()\n",
    "\n",
    "    # Plots (per function folder)\n",
    "    for (idx, f, _mode, _xi, _beta, _report, gp), x_next in zip(debug_rows, next_points):\n",
    "        fdir = ensure_func_plot_dir(idx)\n",
    "        plot_y_over_iterations(idx, f.key, f.y, fdir / \"y_over_iterations.png\")\n",
    "        if f.dim == 2:\n",
    "            plot_2d_gp_mean_contour(idx, f.key, gp, f.X, f.y, x_next, fdir / \"gp_mean_contour.png\")\n",
    "        else:\n",
    "            plot_pca_scatter(idx, f.key, f.X, f.y, x_next, fdir / \"pca_scatter.png\")\n",
    "\n",
    "    print(f\"\\nSaved plots under: {PLOTS_DIR.resolve()}\")\n",
    "    print(f\"Saved history snapshot: {snapshot_path.resolve()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
